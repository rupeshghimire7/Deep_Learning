{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2d9a87",
   "metadata": {},
   "source": [
    "## Machine Translation using Seq2Seq LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a6076",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "674622d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31496391",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4e5d27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135837</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135838</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135839</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135840</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135841</th>\n",
       "      <td>It may be impossible to get a completely error...</td>\n",
       "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                    Run!   \n",
       "2                                                    Run!   \n",
       "3                                                    Wow!   \n",
       "4                                                   Fire!   \n",
       "...                                                   ...   \n",
       "135837  A carbon footprint is the amount of carbon dio...   \n",
       "135838  Death is something that we're often discourage...   \n",
       "135839  Since there are usually multiple websites on a...   \n",
       "135840  If someone who doesn't know your background sa...   \n",
       "135841  It may be impossible to get a completely error...   \n",
       "\n",
       "                                                      fra  \n",
       "0                                                    Va !  \n",
       "1                                                 Cours !  \n",
       "2                                                Courez !  \n",
       "3                                              Ça alors !  \n",
       "4                                                Au feu !  \n",
       "...                                                   ...  \n",
       "135837  Une empreinte carbone est la somme de pollutio...  \n",
       "135838  La mort est une chose qu'on nous décourage sou...  \n",
       "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
       "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
       "135841  Il est peut-être impossible d'obtenir un Corpu...  \n",
       "\n",
       "[135842 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table('eng-fra.txt', names=['eng', 'fra'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86a33165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[135841].eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c82ae872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Il est peut-être impossible d'obtenir un Corpus complètement dénué de fautes, étant donnée la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent, nous pourrions être en mesure de réduire les erreurs.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[135841].fra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89498ecb",
   "metadata": {},
   "source": [
    "**As we have so much data, computation time will be high. We will be taking only 20K instances of data from 135K instances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeb845c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>It matters.</td>\n",
       "      <td>C'est important.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41277</th>\n",
       "      <td>Why don't you remember?</td>\n",
       "      <td>Pourquoi ne t'en souviens-tu pas ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109561</th>\n",
       "      <td>All I can say is that I'd rather not go.</td>\n",
       "      <td>Tout ce que je peux dire est que je préférerai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57377</th>\n",
       "      <td>You can't be sure of that.</td>\n",
       "      <td>Vous ne pouvez pas en être sûrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96368</th>\n",
       "      <td>I wish I could have spoken Spanish.</td>\n",
       "      <td>J'aimerais avoir pu parler espagnol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>We'll fight.</td>\n",
       "      <td>Nous combattrons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78795</th>\n",
       "      <td>He writes scripts for TV shows.</td>\n",
       "      <td>Il écrit des scénarios pour des séries télé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62303</th>\n",
       "      <td>What else is on the agenda?</td>\n",
       "      <td>Qu'y a-t-il également à son programme aujourd'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81847</th>\n",
       "      <td>Towns are larger than villages.</td>\n",
       "      <td>Les villes sont plus grandes que les villages.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121628</th>\n",
       "      <td>Try to find out if everything he said is true.</td>\n",
       "      <td>Essayez de savoir si tout ce qu'il a dit est v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   eng  \\\n",
       "1180                                       It matters.   \n",
       "41277                          Why don't you remember?   \n",
       "109561        All I can say is that I'd rather not go.   \n",
       "57377                       You can't be sure of that.   \n",
       "96368              I wish I could have spoken Spanish.   \n",
       "...                                                ...   \n",
       "2422                                      We'll fight.   \n",
       "78795                  He writes scripts for TV shows.   \n",
       "62303                      What else is on the agenda?   \n",
       "81847                  Towns are larger than villages.   \n",
       "121628  Try to find out if everything he said is true.   \n",
       "\n",
       "                                                      fra  \n",
       "1180                                     C'est important.  \n",
       "41277                  Pourquoi ne t'en souviens-tu pas ?  \n",
       "109561  Tout ce que je peux dire est que je préférerai...  \n",
       "57377                    Vous ne pouvez pas en être sûrs.  \n",
       "96368                J'aimerais avoir pu parler espagnol.  \n",
       "...                                                   ...  \n",
       "2422                                    Nous combattrons.  \n",
       "78795        Il écrit des scénarios pour des séries télé.  \n",
       "62303   Qu'y a-t-il également à son programme aujourd'...  \n",
       "81847      Les villes sont plus grandes que les villages.  \n",
       "121628  Essayez de savoir si tout ce qu'il a dit est v...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(10000)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30c08191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>It matters.</td>\n",
       "      <td>C'est important.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41277</td>\n",
       "      <td>Why don't you remember?</td>\n",
       "      <td>Pourquoi ne t'en souviens-tu pas ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109561</td>\n",
       "      <td>All I can say is that I'd rather not go.</td>\n",
       "      <td>Tout ce que je peux dire est que je préférerai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57377</td>\n",
       "      <td>You can't be sure of that.</td>\n",
       "      <td>Vous ne pouvez pas en être sûrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96368</td>\n",
       "      <td>I wish I could have spoken Spanish.</td>\n",
       "      <td>J'aimerais avoir pu parler espagnol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2422</td>\n",
       "      <td>We'll fight.</td>\n",
       "      <td>Nous combattrons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>78795</td>\n",
       "      <td>He writes scripts for TV shows.</td>\n",
       "      <td>Il écrit des scénarios pour des séries télé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>62303</td>\n",
       "      <td>What else is on the agenda?</td>\n",
       "      <td>Qu'y a-t-il également à son programme aujourd'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>81847</td>\n",
       "      <td>Towns are larger than villages.</td>\n",
       "      <td>Les villes sont plus grandes que les villages.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>121628</td>\n",
       "      <td>Try to find out if everything he said is true.</td>\n",
       "      <td>Essayez de savoir si tout ce qu'il a dit est v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                             eng  \\\n",
       "0       1180                                     It matters.   \n",
       "1      41277                         Why don't you remember?   \n",
       "2     109561        All I can say is that I'd rather not go.   \n",
       "3      57377                      You can't be sure of that.   \n",
       "4      96368             I wish I could have spoken Spanish.   \n",
       "...      ...                                             ...   \n",
       "9995    2422                                    We'll fight.   \n",
       "9996   78795                 He writes scripts for TV shows.   \n",
       "9997   62303                     What else is on the agenda?   \n",
       "9998   81847                 Towns are larger than villages.   \n",
       "9999  121628  Try to find out if everything he said is true.   \n",
       "\n",
       "                                                    fra  \n",
       "0                                      C'est important.  \n",
       "1                    Pourquoi ne t'en souviens-tu pas ?  \n",
       "2     Tout ce que je peux dire est que je préférerai...  \n",
       "3                      Vous ne pouvez pas en être sûrs.  \n",
       "4                  J'aimerais avoir pu parler espagnol.  \n",
       "...                                                 ...  \n",
       "9995                                  Nous combattrons.  \n",
       "9996       Il écrit des scénarios pour des séries télé.  \n",
       "9997  Qu'y a-t-il également à son programme aujourd'...  \n",
       "9998     Les villes sont plus grandes que les villages.  \n",
       "9999  Essayez de savoir si tout ce qu'il a dit est v...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35d1fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It matters.</td>\n",
       "      <td>C'est important.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why don't you remember?</td>\n",
       "      <td>Pourquoi ne t'en souviens-tu pas ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All I can say is that I'd rather not go.</td>\n",
       "      <td>Tout ce que je peux dire est que je préférerai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You can't be sure of that.</td>\n",
       "      <td>Vous ne pouvez pas en être sûrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wish I could have spoken Spanish.</td>\n",
       "      <td>J'aimerais avoir pu parler espagnol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>We'll fight.</td>\n",
       "      <td>Nous combattrons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>He writes scripts for TV shows.</td>\n",
       "      <td>Il écrit des scénarios pour des séries télé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>What else is on the agenda?</td>\n",
       "      <td>Qu'y a-t-il également à son programme aujourd'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Towns are larger than villages.</td>\n",
       "      <td>Les villes sont plus grandes que les villages.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Try to find out if everything he said is true.</td>\n",
       "      <td>Essayez de savoir si tout ce qu'il a dit est v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "0                                        It matters.   \n",
       "1                            Why don't you remember?   \n",
       "2           All I can say is that I'd rather not go.   \n",
       "3                         You can't be sure of that.   \n",
       "4                I wish I could have spoken Spanish.   \n",
       "...                                              ...   \n",
       "9995                                    We'll fight.   \n",
       "9996                 He writes scripts for TV shows.   \n",
       "9997                     What else is on the agenda?   \n",
       "9998                 Towns are larger than villages.   \n",
       "9999  Try to find out if everything he said is true.   \n",
       "\n",
       "                                                    fra  \n",
       "0                                      C'est important.  \n",
       "1                    Pourquoi ne t'en souviens-tu pas ?  \n",
       "2     Tout ce que je peux dire est que je préférerai...  \n",
       "3                      Vous ne pouvez pas en être sûrs.  \n",
       "4                  J'aimerais avoir pu parler espagnol.  \n",
       "...                                                 ...  \n",
       "9995                                  Nous combattrons.  \n",
       "9996       Il écrit des scénarios pour des séries télé.  \n",
       "9997  Qu'y a-t-il également à son programme aujourd'...  \n",
       "9998     Les villes sont plus grandes que les villages.  \n",
       "9999  Essayez de savoir si tout ce qu'il a dit est v...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('index', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd781e3",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "(we will not perform stop words removal and lemmatization and other tasks)\n",
    "\n",
    "* lowercasing\n",
    "* remove punctuations\n",
    "* remove extra spaces\n",
    "* appending `<SOS>` and `<EOS>` tokens in french data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b85ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eng = data.eng.apply(lambda x: x.lower())\n",
    "data.fra = data.fra.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32e65fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_of_punctuations = set(string.punctuation)\n",
    "sets_of_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "620c1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets of punctuations doesn't contain \" ' \" symbol. We will remove it separately.\n",
    "\n",
    "data[\"eng\"] = data[\"eng\"].apply(lambda x: re.sub(\"'\", '', x))\n",
    "data[\"fra\"] = data[\"fra\"].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8045169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eng = data.eng.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))\n",
    "data.fra = data.fra.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "997f4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uneven space removal\n",
    "data[\"eng\"] = data[\"eng\"].apply(lambda x:re.sub(\"\\s+\",\" \",x))\n",
    "data[\"fra\"] = data[\"fra\"].apply(lambda x:re.sub(\"\\s+\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4f3a9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it matters</td>\n",
       "      <td>cest important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why dont you remember</td>\n",
       "      <td>pourquoi ne ten souvienstu pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all i can say is that id rather not go</td>\n",
       "      <td>tout ce que je peux dire est que je préférerai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you cant be sure of that</td>\n",
       "      <td>vous ne pouvez pas en être sûrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish i could have spoken spanish</td>\n",
       "      <td>jaimerais avoir pu parler espagnol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>well fight</td>\n",
       "      <td>nous combattrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>he writes scripts for tv shows</td>\n",
       "      <td>il écrit des scénarios pour des séries télé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>what else is on the agenda</td>\n",
       "      <td>quy atil également à son programme aujourdhui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>towns are larger than villages</td>\n",
       "      <td>les villes sont plus grandes que les villages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>try to find out if everything he said is true</td>\n",
       "      <td>essayez de savoir si tout ce quil a dit est vrai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                eng  \\\n",
       "0                                        it matters   \n",
       "1                             why dont you remember   \n",
       "2            all i can say is that id rather not go   \n",
       "3                          you cant be sure of that   \n",
       "4                i wish i could have spoken spanish   \n",
       "...                                             ...   \n",
       "9995                                     well fight   \n",
       "9996                 he writes scripts for tv shows   \n",
       "9997                     what else is on the agenda   \n",
       "9998                 towns are larger than villages   \n",
       "9999  try to find out if everything he said is true   \n",
       "\n",
       "                                                    fra  \n",
       "0                                        cest important  \n",
       "1                       pourquoi ne ten souvienstu pas   \n",
       "2     tout ce que je peux dire est que je préférerai...  \n",
       "3                       vous ne pouvez pas en être sûrs  \n",
       "4                    jaimerais avoir pu parler espagnol  \n",
       "...                                                 ...  \n",
       "9995                                   nous combattrons  \n",
       "9996        il écrit des scénarios pour des séries télé  \n",
       "9997      quy atil également à son programme aujourdhui  \n",
       "9998      les villes sont plus grandes que les villages  \n",
       "9999   essayez de savoir si tout ce quil a dit est vrai  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bfe5a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it matters</td>\n",
       "      <td>&lt;START&gt; cest important &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why dont you remember</td>\n",
       "      <td>&lt;START&gt; pourquoi ne ten souvienstu pas  &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all i can say is that id rather not go</td>\n",
       "      <td>&lt;START&gt; tout ce que je peux dire est que je pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you cant be sure of that</td>\n",
       "      <td>&lt;START&gt; vous ne pouvez pas en être sûrs &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish i could have spoken spanish</td>\n",
       "      <td>&lt;START&gt; jaimerais avoir pu parler espagnol &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>well fight</td>\n",
       "      <td>&lt;START&gt; nous combattrons &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>he writes scripts for tv shows</td>\n",
       "      <td>&lt;START&gt; il écrit des scénarios pour des séries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>what else is on the agenda</td>\n",
       "      <td>&lt;START&gt; quy atil également à son programme auj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>towns are larger than villages</td>\n",
       "      <td>&lt;START&gt; les villes sont plus grandes que les v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>try to find out if everything he said is true</td>\n",
       "      <td>&lt;START&gt; essayez de savoir si tout ce quil a di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                eng  \\\n",
       "0                                        it matters   \n",
       "1                             why dont you remember   \n",
       "2            all i can say is that id rather not go   \n",
       "3                          you cant be sure of that   \n",
       "4                i wish i could have spoken spanish   \n",
       "...                                             ...   \n",
       "9995                                     well fight   \n",
       "9996                 he writes scripts for tv shows   \n",
       "9997                     what else is on the agenda   \n",
       "9998                 towns are larger than villages   \n",
       "9999  try to find out if everything he said is true   \n",
       "\n",
       "                                                    fra  \n",
       "0                          <START> cest important <END>  \n",
       "1         <START> pourquoi ne ten souvienstu pas  <END>  \n",
       "2     <START> tout ce que je peux dire est que je pr...  \n",
       "3         <START> vous ne pouvez pas en être sûrs <END>  \n",
       "4      <START> jaimerais avoir pu parler espagnol <END>  \n",
       "...                                                 ...  \n",
       "9995                     <START> nous combattrons <END>  \n",
       "9996  <START> il écrit des scénarios pour des séries...  \n",
       "9997  <START> quy atil également à son programme auj...  \n",
       "9998  <START> les villes sont plus grandes que les v...  \n",
       "9999  <START> essayez de savoir si tout ce quil a di...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fra = data.fra.apply(lambda x: \"<START> \"+x+\" <END>\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a75c11df",
   "metadata": {},
   "source": [
    "### Tokenization and Vocab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bbba2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_vocab = set()\n",
    "for sentence in data.eng:\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if word not in all_eng_vocab:\n",
    "            all_eng_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e43c1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fra_vocab = set()\n",
    "for sentence in data.fra:\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if word not in all_fra_vocab:\n",
    "            all_fra_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1793d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "## find max length of English (Source/Input) sentences as well as French (Target) sentences\n",
    "\n",
    "sequence_length = []\n",
    "for sents in data.eng:\n",
    "    sequence_length.append(len(sents.split(' ')))\n",
    "max_length_eng = np.max(sequence_length)\n",
    "print(max_length_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "860bf448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "sequence_length = []\n",
    "for sents in data.fra:\n",
    "    sequence_length.append(len(sents.split(' ')))\n",
    "max_length_fra = np.max(sequence_length)\n",
    "print(max_length_fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce9c5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we can see max length of sentence in input is 28 and for target is 35. \n",
    "# Note that it can change when notebook is rerun as we have sampled 20k instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f70692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(all_eng_vocab)\n",
    "target_words = sorted(all_fra_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0b6c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4824 7770\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "\n",
    "print(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4360c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 7771)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For zero padding we add one extra token\n",
    "num_decoder_tokens += 1\n",
    "num_encoder_tokens += 1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1636dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create word to index & index to word dictionaries\n",
    "\n",
    "# word to idx (stoi)\n",
    "input_token_index = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i + 1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# idx to words (itos)\n",
    "input_index_token = dict((i, word) for word, i in input_token_index.items())\n",
    "target_index_token = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab8336",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "159a7684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8500,), (1500,), (8500,), (1500,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.eng\n",
    "y = data.fra\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8ef5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    '''Function to generate a batch of data '''\n",
    "    for j in range(0, len(X), batch_size):\n",
    "        encoder_input_data = np.zeros((max_length_eng, batch_size),dtype='float32')\n",
    "        decoder_input_data = np.zeros((max_length_fra, batch_size),dtype='float32')\n",
    "        decoder_target_data = np.zeros((max_length_fra, batch_size ,num_decoder_tokens),dtype='float32')\n",
    "        for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "            for t, word in enumerate(input_text.split()):\n",
    "                encoder_input_data[t, i] = input_token_index[word] # encoder input seq\n",
    "            for t, word in enumerate(target_text.split()):\n",
    "                if t<len(target_text.split())-1:\n",
    "                    decoder_input_data[t, i] = target_token_index[word] # decoder input seq\n",
    "                if t>0:\n",
    "                    # decoder target sequence (one hot encoded)\n",
    "                    # does not include the START_ token\n",
    "                    # Offset by one timestep\n",
    "                    decoder_target_data[t-1, i , target_token_index[word]] = 1.\n",
    "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d25b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the Encoder\n",
    "encoder_input_data = np.zeros((len(data.eng), max_length_eng),dtype='float16')\n",
    "\n",
    "# output from the encoder or input to the decoder\n",
    "decoder_input_data = np.zeros((len(data.fra), max_length_fra),dtype='float16')\n",
    "\n",
    "# output by the decoder\n",
    "decoder_target_data = np.zeros((len(data.fra), max_length_fra, num_decoder_tokens),dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d500f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(data.eng, data.fra)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder target data is ahead of decoder input by one timestep\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007cb78",
   "metadata": {},
   "source": [
    "### Model Architecture: Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "336990fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f00e4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "        encoder_states = [hidden_state,cell_state]\n",
    "\n",
    "        return encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "488bc946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(4825, 50)\n",
      "  (LSTM): LSTM(50, 50)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(num_encoder_tokens, latent_dim, latent_dim)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c87a18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # Size of the one hot vectors that will be the input to the decoder\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Output size of the word embedding NN\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Size of the one hot vectors that will be the output of the decoder\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, enc_states):\n",
    "        x = x.unsqueeze(0)\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # (passing encoder's hs, cs - context vectors)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, enc_states)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        decoder_states = (hidden_state, cell_state)\n",
    "\n",
    "        return predictions, decoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38bca78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(7771, 50)\n",
      "  (LSTM): LSTM(50, 50)\n",
      "  (fc): Linear(in_features=50, out_features=7771, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5264084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.Encoder_LSTM = Encoder_LSTM\n",
    "        self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "    def forward(self, source, target, tfr=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = num_decoder_tokens\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "\n",
    "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
    "\n",
    "        x = target[0]\n",
    "\n",
    "        for i in range(1, target_len):\n",
    "            output, ( hidden_state, cell_state ) = self.Decoder_LSTM(x, (hidden_state, cell_state))\n",
    "            outputs[i] = output\n",
    "            best_guess = output.argmax(1) # 1st dimension is word embedding, 0th dimension is batchsize\n",
    "            x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a795920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "step = 0\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9597e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some model hyperparameters\n",
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 256\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bde8b702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 / 10\n",
      "Iterations / loss -  0 / 9.00987434387207\n",
      "\n",
      "Iterations / loss -  1 / 8.932024002075195\n",
      "\n",
      "Iterations / loss -  2 / 8.873627662658691\n",
      "\n",
      "Iterations / loss -  3 / 8.81226921081543\n",
      "\n",
      "Iterations / loss -  4 / 8.771747589111328\n",
      "\n",
      "Iterations / loss -  5 / 8.741626739501953\n",
      "\n",
      "Iterations / loss -  6 / 8.514213562011719\n",
      "\n",
      "Iterations / loss -  7 / 8.362236976623535\n",
      "\n",
      "Iterations / loss -  8 / 8.293224334716797\n",
      "\n",
      "Iterations / loss -  9 / 8.1569185256958\n",
      "\n",
      "Iterations / loss -  10 / 8.068642616271973\n",
      "\n",
      "Iterations / loss -  11 / 7.958271026611328\n",
      "\n",
      "Iterations / loss -  12 / 7.97873592376709\n",
      "\n",
      "Iterations / loss -  13 / 7.722585678100586\n",
      "\n",
      "Iterations / loss -  14 / 7.601340293884277\n",
      "\n",
      "Iterations / loss -  15 / 7.468379020690918\n",
      "\n",
      "Iterations / loss -  16 / 7.36539363861084\n",
      "\n",
      "Iterations / loss -  17 / 7.312774181365967\n",
      "\n",
      "Iterations / loss -  18 / 7.182806491851807\n",
      "\n",
      "Iterations / loss -  19 / 6.935685157775879\n",
      "\n",
      "Iterations / loss -  20 / 6.814390659332275\n",
      "\n",
      "Iterations / loss -  21 / 6.725342273712158\n",
      "\n",
      "Iterations / loss -  22 / 6.601620197296143\n",
      "\n",
      "Iterations / loss -  23 / 6.411056041717529\n",
      "\n",
      "Iterations / loss -  24 / 6.316988945007324\n",
      "\n",
      "Iterations / loss -  25 / 6.162721157073975\n",
      "\n",
      "Iterations / loss -  26 / 6.036289691925049\n",
      "\n",
      "Iterations / loss -  27 / 5.956451416015625\n",
      "\n",
      "Iterations / loss -  28 / 5.7733001708984375\n",
      "\n",
      "Iterations / loss -  29 / 5.651002407073975\n",
      "\n",
      "Iterations / loss -  30 / 5.5233073234558105\n",
      "\n",
      "Iterations / loss -  31 / 5.425156593322754\n",
      "\n",
      "Iterations / loss -  32 / 5.257267475128174\n",
      "\n",
      "Iterations / loss -  33 / 4.487687587738037\n",
      "\n",
      "Epoch - 2 / 10\n",
      "Iterations / loss -  0 / 5.056529521942139\n",
      "\n",
      "Iterations / loss -  1 / 4.910515308380127\n",
      "\n",
      "Iterations / loss -  2 / 4.82157039642334\n",
      "\n",
      "Iterations / loss -  3 / 4.61115026473999\n",
      "\n",
      "Iterations / loss -  4 / 4.490296840667725\n",
      "\n",
      "Iterations / loss -  5 / 4.329738140106201\n",
      "\n",
      "Iterations / loss -  6 / 4.287292957305908\n",
      "\n",
      "Iterations / loss -  7 / 4.035308361053467\n",
      "\n",
      "Iterations / loss -  8 / 4.001673221588135\n",
      "\n",
      "Iterations / loss -  9 / 3.8608129024505615\n",
      "\n",
      "Iterations / loss -  10 / 3.764021396636963\n",
      "\n",
      "Iterations / loss -  11 / 3.648794651031494\n",
      "\n",
      "Iterations / loss -  12 / 3.4915425777435303\n",
      "\n",
      "Iterations / loss -  13 / 3.418520450592041\n",
      "\n",
      "Iterations / loss -  14 / 3.207352638244629\n",
      "\n",
      "Iterations / loss -  15 / 3.1386616230010986\n",
      "\n",
      "Iterations / loss -  16 / 2.9886465072631836\n",
      "\n",
      "Iterations / loss -  17 / 2.9619905948638916\n",
      "\n",
      "Iterations / loss -  18 / 2.911017417907715\n",
      "\n",
      "Iterations / loss -  19 / 2.7411837577819824\n",
      "\n",
      "Iterations / loss -  20 / 2.6963813304901123\n",
      "\n",
      "Iterations / loss -  21 / 2.609158515930176\n",
      "\n",
      "Iterations / loss -  22 / 2.5465943813323975\n",
      "\n",
      "Iterations / loss -  23 / 2.5138745307922363\n",
      "\n",
      "Iterations / loss -  24 / 2.391937255859375\n",
      "\n",
      "Iterations / loss -  25 / 2.3611226081848145\n",
      "\n",
      "Iterations / loss -  26 / 2.2749059200286865\n",
      "\n",
      "Iterations / loss -  27 / 2.294281482696533\n",
      "\n",
      "Iterations / loss -  28 / 2.1724283695220947\n",
      "\n",
      "Iterations / loss -  29 / 2.1762046813964844\n",
      "\n",
      "Iterations / loss -  30 / 2.1043028831481934\n",
      "\n",
      "Iterations / loss -  31 / 2.082606077194214\n",
      "\n",
      "Iterations / loss -  32 / 2.033950090408325\n",
      "\n",
      "Iterations / loss -  33 / 0.9575222730636597\n",
      "\n",
      "Epoch - 3 / 10\n",
      "Iterations / loss -  0 / 2.0292558670043945\n",
      "\n",
      "Iterations / loss -  1 / 1.9820621013641357\n",
      "\n",
      "Iterations / loss -  2 / 2.011359691619873\n",
      "\n",
      "Iterations / loss -  3 / 1.9005422592163086\n",
      "\n",
      "Iterations / loss -  4 / 1.894837498664856\n",
      "\n",
      "Iterations / loss -  5 / 1.802857756614685\n",
      "\n",
      "Iterations / loss -  6 / 1.8743551969528198\n",
      "\n",
      "Iterations / loss -  7 / 1.7431398630142212\n",
      "\n",
      "Iterations / loss -  8 / 1.8848835229873657\n",
      "\n",
      "Iterations / loss -  9 / 1.8434555530548096\n",
      "\n",
      "Iterations / loss -  10 / 1.7874246835708618\n",
      "\n",
      "Iterations / loss -  11 / 1.8408503532409668\n",
      "\n",
      "Iterations / loss -  12 / 1.7682639360427856\n",
      "\n",
      "Iterations / loss -  13 / 1.833784818649292\n",
      "\n",
      "Iterations / loss -  14 / 1.7078354358673096\n",
      "\n",
      "Iterations / loss -  15 / 1.746516466140747\n",
      "\n",
      "Iterations / loss -  16 / 1.6699846982955933\n",
      "\n",
      "Iterations / loss -  17 / 1.7562603950500488\n",
      "\n",
      "Iterations / loss -  18 / 1.8111677169799805\n",
      "\n",
      "Iterations / loss -  19 / 1.6930581331253052\n",
      "\n",
      "Iterations / loss -  20 / 1.7546979188919067\n",
      "\n",
      "Iterations / loss -  21 / 1.7376412153244019\n",
      "\n",
      "Iterations / loss -  22 / 1.7395679950714111\n",
      "\n",
      "Iterations / loss -  23 / 1.7911584377288818\n",
      "\n",
      "Iterations / loss -  24 / 1.7001415491104126\n",
      "\n",
      "Iterations / loss -  25 / 1.7311830520629883\n",
      "\n",
      "Iterations / loss -  26 / 1.6885743141174316\n",
      "\n",
      "Iterations / loss -  27 / 1.7787684202194214\n",
      "\n",
      "Iterations / loss -  28 / 1.6957745552062988\n",
      "\n",
      "Iterations / loss -  29 / 1.737174153327942\n",
      "\n",
      "Iterations / loss -  30 / 1.6971114873886108\n",
      "\n",
      "Iterations / loss -  31 / 1.7012388706207275\n",
      "\n",
      "Iterations / loss -  32 / 1.684625267982483\n",
      "\n",
      "Iterations / loss -  33 / 0.6584880948066711\n",
      "\n",
      "Epoch - 4 / 10\n",
      "Iterations / loss -  0 / 1.7331291437149048\n",
      "\n",
      "Iterations / loss -  1 / 1.7212697267532349\n",
      "\n",
      "Iterations / loss -  2 / 1.7539842128753662\n",
      "\n",
      "Iterations / loss -  3 / 1.6591075658798218\n",
      "\n",
      "Iterations / loss -  4 / 1.6647202968597412\n",
      "\n",
      "Iterations / loss -  5 / 1.5770150423049927\n",
      "\n",
      "Iterations / loss -  6 / 1.662858486175537\n",
      "\n",
      "Iterations / loss -  7 / 1.5510368347167969\n",
      "\n",
      "Iterations / loss -  8 / 1.692035436630249\n",
      "\n",
      "Iterations / loss -  9 / 1.6776387691497803\n",
      "\n",
      "Iterations / loss -  10 / 1.6296606063842773\n",
      "\n",
      "Iterations / loss -  11 / 1.68425452709198\n",
      "\n",
      "Iterations / loss -  12 / 1.6400772333145142\n",
      "\n",
      "Iterations / loss -  13 / 1.687134861946106\n",
      "\n",
      "Iterations / loss -  14 / 1.5789971351623535\n",
      "\n",
      "Iterations / loss -  15 / 1.5904655456542969\n",
      "\n",
      "Iterations / loss -  16 / 1.5483715534210205\n",
      "\n",
      "Iterations / loss -  17 / 1.6357778310775757\n",
      "\n",
      "Iterations / loss -  18 / 1.6940209865570068\n",
      "\n",
      "Iterations / loss -  19 / 1.5661450624465942\n",
      "\n",
      "Iterations / loss -  20 / 1.641616702079773\n",
      "\n",
      "Iterations / loss -  21 / 1.6209423542022705\n",
      "\n",
      "Iterations / loss -  22 / 1.6183217763900757\n",
      "\n",
      "Iterations / loss -  23 / 1.695664882659912\n",
      "\n",
      "Iterations / loss -  24 / 1.6041061878204346\n",
      "\n",
      "Iterations / loss -  25 / 1.6066170930862427\n",
      "\n",
      "Iterations / loss -  26 / 1.5926356315612793\n",
      "\n",
      "Iterations / loss -  27 / 1.681230068206787\n",
      "\n",
      "Iterations / loss -  28 / 1.5885076522827148\n",
      "\n",
      "Iterations / loss -  29 / 1.6456074714660645\n",
      "\n",
      "Iterations / loss -  30 / 1.6128184795379639\n",
      "\n",
      "Iterations / loss -  31 / 1.605671763420105\n",
      "\n",
      "Iterations / loss -  32 / 1.5867750644683838\n",
      "\n",
      "Iterations / loss -  33 / 0.6675273180007935\n",
      "\n",
      "Epoch - 5 / 10\n",
      "Iterations / loss -  0 / 1.6488993167877197\n",
      "\n",
      "Iterations / loss -  1 / 1.6446118354797363\n",
      "\n",
      "Iterations / loss -  2 / 1.6860005855560303\n",
      "\n",
      "Iterations / loss -  3 / 1.5688951015472412\n",
      "\n",
      "Iterations / loss -  4 / 1.582500696182251\n",
      "\n",
      "Iterations / loss -  5 / 1.4965014457702637\n",
      "\n",
      "Iterations / loss -  6 / 1.5781461000442505\n",
      "\n",
      "Iterations / loss -  7 / 1.4673670530319214\n",
      "\n",
      "Iterations / loss -  8 / 1.623469352722168\n",
      "\n",
      "Iterations / loss -  9 / 1.6470460891723633\n",
      "\n",
      "Iterations / loss -  10 / 1.5491458177566528\n",
      "\n",
      "Iterations / loss -  11 / 1.613869071006775\n",
      "\n",
      "Iterations / loss -  12 / 1.5431369543075562\n",
      "\n",
      "Iterations / loss -  13 / 1.6076041460037231\n",
      "\n",
      "Iterations / loss -  14 / 1.5110076665878296\n",
      "\n",
      "Iterations / loss -  15 / 1.542561411857605\n",
      "\n",
      "Iterations / loss -  16 / 1.4732962846755981\n",
      "\n",
      "Iterations / loss -  17 / 1.5691803693771362\n",
      "\n",
      "Iterations / loss -  18 / 1.6160029172897339\n",
      "\n",
      "Iterations / loss -  19 / 1.5076318979263306\n",
      "\n",
      "Iterations / loss -  20 / 1.5567890405654907\n",
      "\n",
      "Iterations / loss -  21 / 1.5614402294158936\n",
      "\n",
      "Iterations / loss -  22 / 1.5789543390274048\n",
      "\n",
      "Iterations / loss -  23 / 1.6249487400054932\n",
      "\n",
      "Iterations / loss -  24 / 1.5292892456054688\n",
      "\n",
      "Iterations / loss -  25 / 1.569993019104004\n",
      "\n",
      "Iterations / loss -  26 / 1.5324550867080688\n",
      "\n",
      "Iterations / loss -  27 / 1.6073269844055176\n",
      "\n",
      "Iterations / loss -  28 / 1.5565481185913086\n",
      "\n",
      "Iterations / loss -  29 / 1.6133095026016235\n",
      "\n",
      "Iterations / loss -  30 / 1.5321056842803955\n",
      "\n",
      "Iterations / loss -  31 / 1.542808175086975\n",
      "\n",
      "Iterations / loss -  32 / 1.5479059219360352\n",
      "\n",
      "Iterations / loss -  33 / 0.6406413316726685\n",
      "\n",
      "Epoch - 6 / 10\n",
      "Iterations / loss -  0 / 1.6164978742599487\n",
      "\n",
      "Iterations / loss -  1 / 1.5648788213729858\n",
      "\n",
      "Iterations / loss -  2 / 1.5969359874725342\n",
      "\n",
      "Iterations / loss -  3 / 1.4977821111679077\n",
      "\n",
      "Iterations / loss -  4 / 1.5196733474731445\n",
      "\n",
      "Iterations / loss -  5 / 1.4724081754684448\n",
      "\n",
      "Iterations / loss -  6 / 1.5353045463562012\n",
      "\n",
      "Iterations / loss -  7 / 1.4698487520217896\n",
      "\n",
      "Iterations / loss -  8 / 1.5554182529449463\n",
      "\n",
      "Iterations / loss -  9 / 1.5473601818084717\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations / loss -  10 / 1.5011496543884277\n",
      "\n",
      "Iterations / loss -  11 / 1.5950796604156494\n",
      "\n",
      "Iterations / loss -  12 / 1.5128573179244995\n",
      "\n",
      "Iterations / loss -  13 / 1.5710408687591553\n",
      "\n",
      "Iterations / loss -  14 / 1.4542452096939087\n",
      "\n",
      "Iterations / loss -  15 / 1.5206581354141235\n",
      "\n",
      "Iterations / loss -  16 / 1.430726170539856\n",
      "\n",
      "Iterations / loss -  17 / 1.5231949090957642\n",
      "\n",
      "Iterations / loss -  18 / 1.582231044769287\n",
      "\n",
      "Iterations / loss -  19 / 1.451737880706787\n",
      "\n",
      "Iterations / loss -  20 / 1.5175186395645142\n",
      "\n",
      "Iterations / loss -  21 / 1.5095438957214355\n",
      "\n",
      "Iterations / loss -  22 / 1.521159291267395\n",
      "\n",
      "Iterations / loss -  23 / 1.5686663389205933\n",
      "\n",
      "Iterations / loss -  24 / 1.4923734664916992\n",
      "\n",
      "Iterations / loss -  25 / 1.5365716218948364\n",
      "\n",
      "Iterations / loss -  26 / 1.5591704845428467\n",
      "\n",
      "Iterations / loss -  27 / 1.594876766204834\n",
      "\n",
      "Iterations / loss -  28 / 1.5253019332885742\n",
      "\n",
      "Iterations / loss -  29 / 1.5667297840118408\n",
      "\n",
      "Iterations / loss -  30 / 1.5632286071777344\n",
      "\n",
      "Iterations / loss -  31 / 1.5620777606964111\n",
      "\n",
      "Iterations / loss -  32 / 1.5688694715499878\n",
      "\n",
      "Iterations / loss -  33 / 0.7233791351318359\n",
      "\n",
      "Epoch - 7 / 10\n",
      "Iterations / loss -  0 / 1.574346899986267\n",
      "\n",
      "Iterations / loss -  1 / 1.574457049369812\n",
      "\n",
      "Iterations / loss -  2 / 1.610733985900879\n",
      "\n",
      "Iterations / loss -  3 / 1.4845751523971558\n",
      "\n",
      "Iterations / loss -  4 / 1.542574167251587\n",
      "\n",
      "Iterations / loss -  5 / 1.4268132448196411\n",
      "\n",
      "Iterations / loss -  6 / 1.504431962966919\n",
      "\n",
      "Iterations / loss -  7 / 1.4741567373275757\n",
      "\n",
      "Iterations / loss -  8 / 1.5400348901748657\n",
      "\n",
      "Iterations / loss -  9 / 1.5484907627105713\n",
      "\n",
      "Iterations / loss -  10 / 1.4761611223220825\n",
      "\n",
      "Iterations / loss -  11 / 1.5217260122299194\n",
      "\n",
      "Iterations / loss -  12 / 1.518437147140503\n",
      "\n",
      "Iterations / loss -  13 / 1.6042160987854004\n",
      "\n",
      "Iterations / loss -  14 / 1.4362335205078125\n",
      "\n",
      "Iterations / loss -  15 / 1.4727821350097656\n",
      "\n",
      "Iterations / loss -  16 / 1.4394890069961548\n",
      "\n",
      "Iterations / loss -  17 / 1.5208290815353394\n",
      "\n",
      "Iterations / loss -  18 / 1.5665817260742188\n",
      "\n",
      "Iterations / loss -  19 / 1.4707881212234497\n",
      "\n",
      "Iterations / loss -  20 / 1.511045217514038\n",
      "\n",
      "Iterations / loss -  21 / 1.5165765285491943\n",
      "\n",
      "Iterations / loss -  22 / 1.5020170211791992\n",
      "\n",
      "Iterations / loss -  23 / 1.6210877895355225\n",
      "\n",
      "Iterations / loss -  24 / 1.4707125425338745\n",
      "\n",
      "Iterations / loss -  25 / 1.5050804615020752\n",
      "\n",
      "Iterations / loss -  26 / 1.4779163599014282\n",
      "\n",
      "Iterations / loss -  27 / 1.564021348953247\n",
      "\n",
      "Iterations / loss -  28 / 1.5231608152389526\n",
      "\n",
      "Iterations / loss -  29 / 1.5392416715621948\n",
      "\n",
      "Iterations / loss -  30 / 1.5492463111877441\n",
      "\n",
      "Iterations / loss -  31 / 1.4976292848587036\n",
      "\n",
      "Iterations / loss -  32 / 1.4838069677352905\n",
      "\n",
      "Iterations / loss -  33 / 0.6815403699874878\n",
      "\n",
      "Epoch - 8 / 10\n",
      "Iterations / loss -  0 / 1.5388565063476562\n",
      "\n",
      "Iterations / loss -  1 / 1.5057623386383057\n",
      "\n",
      "Iterations / loss -  2 / 1.5821213722229004\n",
      "\n",
      "Iterations / loss -  3 / 1.457959532737732\n",
      "\n",
      "Iterations / loss -  4 / 1.475305199623108\n",
      "\n",
      "Iterations / loss -  5 / 1.431738018989563\n",
      "\n",
      "Iterations / loss -  6 / 1.4849507808685303\n",
      "\n",
      "Iterations / loss -  7 / 1.406121015548706\n",
      "\n",
      "Iterations / loss -  8 / 1.5121395587921143\n",
      "\n",
      "Iterations / loss -  9 / 1.496838092803955\n",
      "\n",
      "Iterations / loss -  10 / 1.465559482574463\n",
      "\n",
      "Iterations / loss -  11 / 1.543389081954956\n",
      "\n",
      "Iterations / loss -  12 / 1.4508633613586426\n",
      "\n",
      "Iterations / loss -  13 / 1.512165904045105\n",
      "\n",
      "Iterations / loss -  14 / 1.4203639030456543\n",
      "\n",
      "Iterations / loss -  15 / 1.5167385339736938\n",
      "\n",
      "Iterations / loss -  16 / 1.411732792854309\n",
      "\n",
      "Iterations / loss -  17 / 1.471671223640442\n",
      "\n",
      "Iterations / loss -  18 / 1.5480908155441284\n",
      "\n",
      "Iterations / loss -  19 / 1.4565656185150146\n",
      "\n",
      "Iterations / loss -  20 / 1.4931594133377075\n",
      "\n",
      "Iterations / loss -  21 / 1.4866119623184204\n",
      "\n",
      "Iterations / loss -  22 / 1.4757457971572876\n",
      "\n",
      "Iterations / loss -  23 / 1.5500465631484985\n",
      "\n",
      "Iterations / loss -  24 / 1.4800209999084473\n",
      "\n",
      "Iterations / loss -  25 / 1.4962133169174194\n",
      "\n",
      "Iterations / loss -  26 / 1.4432716369628906\n",
      "\n",
      "Iterations / loss -  27 / 1.5913292169570923\n",
      "\n",
      "Iterations / loss -  28 / 1.4799964427947998\n",
      "\n",
      "Iterations / loss -  29 / 1.5871694087982178\n",
      "\n",
      "Iterations / loss -  30 / 1.498022437095642\n",
      "\n",
      "Iterations / loss -  31 / 1.4939537048339844\n",
      "\n",
      "Iterations / loss -  32 / 1.4597939252853394\n",
      "\n",
      "Iterations / loss -  33 / 0.5248141884803772\n",
      "\n",
      "Epoch - 9 / 10\n",
      "Iterations / loss -  0 / 1.5317163467407227\n",
      "\n",
      "Iterations / loss -  1 / 1.4826771020889282\n",
      "\n",
      "Iterations / loss -  2 / 1.6146811246871948\n",
      "\n",
      "Iterations / loss -  3 / 1.550455927848816\n",
      "\n",
      "Iterations / loss -  4 / 1.465911865234375\n",
      "\n",
      "Iterations / loss -  5 / 1.3880302906036377\n",
      "\n",
      "Iterations / loss -  6 / 1.4782096147537231\n",
      "\n",
      "Iterations / loss -  7 / 1.3731939792633057\n",
      "\n",
      "Iterations / loss -  8 / 1.5188077688217163\n",
      "\n",
      "Iterations / loss -  9 / 1.498852252960205\n",
      "\n",
      "Iterations / loss -  10 / 1.453869342803955\n",
      "\n",
      "Iterations / loss -  11 / 1.503624677658081\n",
      "\n",
      "Iterations / loss -  12 / 1.4359344244003296\n",
      "\n",
      "Iterations / loss -  13 / 1.49937903881073\n",
      "\n",
      "Iterations / loss -  14 / 1.410577416419983\n",
      "\n",
      "Iterations / loss -  15 / 1.4274365901947021\n",
      "\n",
      "Iterations / loss -  16 / 1.3867907524108887\n",
      "\n",
      "Iterations / loss -  17 / 1.4791322946548462\n",
      "\n",
      "Iterations / loss -  18 / 1.5213611125946045\n",
      "\n",
      "Iterations / loss -  19 / 1.42904531955719\n",
      "\n",
      "Iterations / loss -  20 / 1.479015588760376\n",
      "\n",
      "Iterations / loss -  21 / 1.496649146080017\n",
      "\n",
      "Iterations / loss -  22 / 1.4837067127227783\n",
      "\n",
      "Iterations / loss -  23 / 1.5362718105316162\n",
      "\n",
      "Iterations / loss -  24 / 1.4448482990264893\n",
      "\n",
      "Iterations / loss -  25 / 1.490991473197937\n",
      "\n",
      "Iterations / loss -  26 / 1.4377597570419312\n",
      "\n",
      "Iterations / loss -  27 / 1.5735986232757568\n",
      "\n",
      "Iterations / loss -  28 / 1.5002611875534058\n",
      "\n",
      "Iterations / loss -  29 / 1.5017812252044678\n",
      "\n",
      "Iterations / loss -  30 / 1.484604835510254\n",
      "\n",
      "Iterations / loss -  31 / 1.488178014755249\n",
      "\n",
      "Iterations / loss -  32 / 1.4699593782424927\n",
      "\n",
      "Iterations / loss -  33 / 0.5328221321105957\n",
      "\n",
      "Epoch - 10 / 10\n",
      "Iterations / loss -  0 / 1.5102747678756714\n",
      "\n",
      "Iterations / loss -  1 / 1.50917387008667\n",
      "\n",
      "Iterations / loss -  2 / 1.5605298280715942\n",
      "\n",
      "Iterations / loss -  3 / 1.436437726020813\n",
      "\n",
      "Iterations / loss -  4 / 1.4589593410491943\n",
      "\n",
      "Iterations / loss -  5 / 1.3700724840164185\n",
      "\n",
      "Iterations / loss -  6 / 1.455786108970642\n",
      "\n",
      "Iterations / loss -  7 / 1.3892334699630737\n",
      "\n",
      "Iterations / loss -  8 / 1.4938448667526245\n",
      "\n",
      "Iterations / loss -  9 / 1.4783381223678589\n",
      "\n",
      "Iterations / loss -  10 / 1.438462734222412\n",
      "\n",
      "Iterations / loss -  11 / 1.4617754220962524\n",
      "\n",
      "Iterations / loss -  12 / 1.5009448528289795\n",
      "\n",
      "Iterations / loss -  13 / 1.5412029027938843\n",
      "\n",
      "Iterations / loss -  14 / 1.382098913192749\n",
      "\n",
      "Iterations / loss -  15 / 1.4210463762283325\n",
      "\n",
      "Iterations / loss -  16 / 1.3765969276428223\n",
      "\n",
      "Iterations / loss -  17 / 1.467777132987976\n",
      "\n",
      "Iterations / loss -  18 / 1.5249998569488525\n",
      "\n",
      "Iterations / loss -  19 / 1.4009699821472168\n",
      "\n",
      "Iterations / loss -  20 / 1.4417545795440674\n",
      "\n",
      "Iterations / loss -  21 / 1.4728668928146362\n",
      "\n",
      "Iterations / loss -  22 / 1.4550299644470215\n",
      "\n",
      "Iterations / loss -  23 / 1.5659880638122559\n",
      "\n",
      "Iterations / loss -  24 / 1.4381157159805298\n",
      "\n",
      "Iterations / loss -  25 / 1.4551136493682861\n",
      "\n",
      "Iterations / loss -  26 / 1.4256975650787354\n",
      "\n",
      "Iterations / loss -  27 / 1.5190268754959106\n",
      "\n",
      "Iterations / loss -  28 / 1.4425294399261475\n",
      "\n",
      "Iterations / loss -  29 / 1.488203525543213\n",
      "\n",
      "Iterations / loss -  30 / 1.458391547203064\n",
      "\n",
      "Iterations / loss -  31 / 1.4826462268829346\n",
      "\n",
      "Iterations / loss -  32 / 1.4212173223495483\n",
      "\n",
      "Iterations / loss -  33 / 0.5081063508987427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epoch_loss = 0.0\n",
    "best_loss = 999999\n",
    "losses = []\n",
    "best_epoch = -1\n",
    "ts1  = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_list = []\n",
    "    print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "\n",
    "\n",
    "    model.train(True)\n",
    "    for batch_idx, ( input_data, target_data ) in enumerate(generate_batch(batch_size=batch_size)):\n",
    "        input_data_enc = torch.tensor(input_data[0]).long()\n",
    "        input_data_dec = torch.tensor(input_data[1]).long()\n",
    "        target = torch.tensor(target_data.argmax(2)).long()\n",
    "\n",
    "        # Pass the input and target for model's forward method\n",
    "        output = model(input_data_enc, target)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        # Clear the accumulating gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate the loss value for every epoch\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Calculate the gradients for weights & biases using back-propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights values using the gradients we calculated using bp\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss_list.append(loss.item())\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "        if ((epoch - best_epoch) >= 10):\n",
    "            print(\"no improvement in 10 epochs, break\")\n",
    "            break\n",
    "        print(\"Iterations / loss -  {} / {}\".format(batch_idx,loss.item()))\n",
    "        print()\n",
    "    losses.append(np.mean(epoch_loss_list))\n",
    "\n",
    "torch.save({\n",
    "          'model_state_dict': model.state_dict(),\n",
    "          'loss': losses\n",
    "          },\"lstm_seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a77ea157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.433918041341445"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = losses[-1]\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8510c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(Encoder(num_encoder_tokens, latent_dim, latent_dim), Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens))\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"lstm_seq2seq\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "def decode_sequence(sentence, max_length=50):\n",
    "    model.eval()\n",
    "    # lower, removing punctuations,\n",
    "    tokens =  (''.join(char for char in re.sub(\" +\", \" \", re.sub(\"'\", '', sentence).lower()) if char not in sets_of_punctuations)).split()\n",
    "\n",
    "    text_to_indices = [ input_token_index[token] for token in tokens]\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    outputs = [target_token_index[\"<START>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, ( hidden, cell ) = model.Decoder_LSTM(previous_word, (hidden, cell))\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if best_guess == \"<END>\":\n",
    "            break\n",
    "#     print(\"Outputs\", outputs)\n",
    "\n",
    "    translated_sentence = [target_index_token.get(idx,'<PAD>') for idx in outputs]\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "087c6db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START>'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_index_token[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a2920b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs [40, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input English sentence: what would we do instead\n",
      "Actual French Translation: <START> que ferionsnous à la place  <END>\n",
      "Predicted French Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted French Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9390dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: i cried a lot\n",
      "Actual Chinese Translation: <START> jai beaucoup pleuré <END>\n",
      "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a522d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
