{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_Z-N7Ylp0-Gi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0ce13b5ea561fdc64db96b3016ced66",
     "grade": false,
     "grade_id": "cell-5c7c35e5db56651f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Machine Translation using Sequence to Sequence LSTM networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7BEzkQrJ0-Gn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c09f58dd19c22fd8c14a82ecfdb3ad36",
     "grade": false,
     "grade_id": "cell-86a6d09c34d33f25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Machine translation refers to the use of machines or software to translate text to speech or speech from one language to another language.\n",
    "\n",
    "In this assignment we will work out the demonstration of how we can apply the LSTM networks to translate speech from one language to another.\n",
    "\n",
    "We will be translating sequences from English to Chinese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pGuEgkXT0-Gn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aaf14ad60b6057ae5ef2f283fae3a801",
     "grade": false,
     "grade_id": "cell-e29498e719ab95c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Datasets\n",
    "We will be using this dataset. https://www.manythings.org/anki/cmn-eng.zip.\n",
    "\n",
    "Few samples of the dataset looks as follows:\n",
    "\n",
    "**$ENGLISH \\hspace{10mm} CHINESE$**\n",
    "\n",
    "$Go. \\hspace{30mm} 走 $\n",
    "\n",
    "$Run! \\hspace{30mm} 跑!$\n",
    "\n",
    "$Fire! \\hspace{30mm} A火！$\n",
    "\n",
    "$Help! \\hspace{30mm} 救命!$\n",
    "\n",
    "$Jump. \\hspace{30mm} 跳.$\n",
    "\n",
    "$Stop! \\hspace{30mm} 停止!$\n",
    "\n",
    "We can see that on the left column, we have a list of english sequences like, GO, RUN, FIRE, HELP, etc and on the right we have their respective CHINESE tranlsations.\n",
    "\n",
    "Here, the input to the model will be the list of English sentences and the target will be the list of Chinese translations.\n",
    "\n",
    "Here in the dataset,\n",
    "\n",
    "We will follow the following steps duing the machine translation:\n",
    "\n",
    "1. Preprocess the training sequenes\n",
    "2. Develop sequence to sequence LSTM model\n",
    "3. Train LSTM model\n",
    "4. Evalute model by testing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AxGshOMk6_n9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fc6f0c2167c4587dc68f0dcbeeac76e",
     "grade": false,
     "grade_id": "cell-322635f771076732",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZCo5hAFPw6MR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "453a2c02cdbbb02cb0046e352998d837",
     "grade": false,
     "grade_id": "cell-92d78258255f0c3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "deletable": false,
    "editable": false,
    "id": "UrdGrSJoxC3o",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe69062cf677017d2c47b789df0f9a32",
     "grade": false,
     "grade_id": "cell-64ea11783dd9398f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "938a02a7-b593-4035-e2ef-cda714163fa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-caeccad8-f058-479b-be7c-150c72e6ea19\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-caeccad8-f058-479b-be7c-150c72e6ea19\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cmn.txt to cmn (1).txt\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vU1L7fAckbxe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca7a41a47f2a4f4c921145cb562375bc",
     "grade": false,
     "grade_id": "cell-949aff3298d2f0f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's read the dataset from the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mQgGzF147E-j",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56425b9d799dd5ce1268301ab7c58c7e",
     "grade": false,
     "grade_id": "cell-f81b84edf1b80a87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "deletable": false,
    "editable": false,
    "id": "9VCyVeGew6MT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcc930cecb546092836f694d5b4ce982",
     "grade": false,
     "grade_id": "cell-3cdcf87702aba82a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "e8d777a2-74d9-4200-ad2f-0fca2ad93d79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-488f2306-cad2-4e14-b549-7b078e187bf8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>chin</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>嗨。</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>你好。</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run.</td>\n",
       "      <td>你用跑的。</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>等等！</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>等一下！</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>When did she promise to meet him?</td>\n",
       "      <td>她答应几时见他？</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>When did you change your address?</td>\n",
       "      <td>你什麼時候更改了你的地址?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>When did your baby start talking?</td>\n",
       "      <td>你的寶寶，什麼時候開始說話的？</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>When was this university founded?</td>\n",
       "      <td>这所大学是什么时候建的？</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>Where are you going to eat lunch?</td>\n",
       "      <td>你要去哪裡吃午飯？</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15857 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-488f2306-cad2-4e14-b549-7b078e187bf8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-488f2306-cad2-4e14-b549-7b078e187bf8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-488f2306-cad2-4e14-b549-7b078e187bf8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                     eng             chin  \\\n",
       "0                                    Hi.               嗨。   \n",
       "1                                    Hi.              你好。   \n",
       "2                                   Run.            你用跑的。   \n",
       "3                                  Wait!              等等！   \n",
       "4                                  Wait!             等一下！   \n",
       "...                                  ...              ...   \n",
       "15852  When did she promise to meet him?         她答应几时见他？   \n",
       "15853  When did you change your address?    你什麼時候更改了你的地址?   \n",
       "15854  When did your baby start talking?  你的寶寶，什麼時候開始說話的？   \n",
       "15855  When was this university founded?     这所大学是什么时候建的？   \n",
       "15856  Where are you going to eat lunch?        你要去哪裡吃午飯？   \n",
       "\n",
       "                                                    info  \n",
       "0      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "1      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "2      CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "3      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "4      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "...                                                  ...  \n",
       "15852  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "15853  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "15854  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "15855  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "15856             CC-BY 2.0 (France) Attribution: tatoeb  \n",
       "\n",
       "[15857 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lines = pd.read_table('/content/drive/MyDrive/Colab Notebooks/cmn.txt', names=['eng', 'chin', 'info'])\n",
    "lines = pd.read_table('./cmn.txt', names=['eng', 'chin', 'info'])\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dvqLeT1hkS_1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4602bba070f00465a7f411ce333ea381",
     "grade": false,
     "grade_id": "cell-109bf8e6353d477b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We are concerned with only english to chinese translation, so we choose these two columns.\n",
    "### Exercise 1\n",
    "#### Task 1\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "* Select the English and Chinese translation columns\n",
    "* Select the first 10,000 samples and store it on `lines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "id": "txXegvQykUFr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11a7c082ad344bbf53fbc79a134ca6a5",
     "grade": false,
     "grade_id": "cell-8d554e7a8fae2b5f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-1-Task-1\n",
    "# lines = None\n",
    "\n",
    "# Select `eng` and `chin` columns from the table\n",
    "# take only first 10,000 samples to train\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "lines = lines[[\"eng\",\"chin\"]][:10000]\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zgYFaXI_0-Gr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3d1a3f4c8d47e319282102289d91b29",
     "grade": true,
     "grade_id": "cell-cc75ee800e422bec",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert lines is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Kh7IpJH-w6MT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd3454c7013d5e967f924cdf40bec69",
     "grade": false,
     "grade_id": "cell-c1a557d4e1f790be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "3667d599-f680-4cf5-b19e-84146df0d954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying shape of the training set\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qJqfTx_S7MBm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a3fefeb3dbff03a8151d1ceafe32a43",
     "grade": false,
     "grade_id": "cell-6f124aca6532ebf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1p_OI3gCm1nY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69ae6492cb816a54dd76e1158feb7ff8",
     "grade": false,
     "grade_id": "cell-12b91bc6ebf516bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will follow the following preprocessing steps in order to clean the dataset and fit into model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9OavBlnl0-Gs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0e3ec6a0dcb40c939ed480e66929e06",
     "grade": false,
     "grade_id": "cell-55d8579a96347262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ayVesOcK0-Gs",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a573be3cc12561afab4c01b19ce01795",
     "grade": false,
     "grade_id": "cell-818a7628e07222c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# lowercase inputs on the columns\n",
    "lines.eng = lines.eng.apply(lambda x: x.lower())\n",
    "lines.chin = lines.chin.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ePdmVLLlw6MU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f8bf7c2439c84eb248d1b09d073edf",
     "grade": false,
     "grade_id": "cell-ae96a6b81a1185d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Above, we just performed lowercasing of the input samples. Lowercasing is the first operation we performed. Now, we will perform other operations like: `Removing Quotes`, `Removing Special Characters`, `Removing Uneven Spaces`, `Adding <START> and <END> tokens`, etc. Perform similar implementations like that mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d-vf6AbR0-Gs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "068af81cad8ab07cbbceb9a3cbccd94d",
     "grade": false,
     "grade_id": "cell-88c2f1ffb428de99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Removing Quotes\n",
    "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
    "#### Task 1\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "id": "cnxN3CNhw6MU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24f6e9de968fb417c8bddc9654cbe58b",
     "grade": false,
     "grade_id": "cell-166a4b682ff40791",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-2-Task-1\n",
    "\n",
    "# remove all the quotes \"'\" from the columns\n",
    "\n",
    "# lines.eng = None\n",
    "# lines.chin = None\n",
    "\n",
    "# Exercise 2 | Task 1\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "lines[\"eng\"] = lines[\"eng\"].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines[\"chin\"] = lines[\"chin\"].apply(lambda x: re.sub(\"'\", '', x))\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EFKIDmSg0-Gt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8533a681c6890484e1bd4547c9a4380a",
     "grade": true,
     "grade_id": "cell-71fafecfa7e89a02",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert lines.eng is not None\n",
    "assert lines.chin is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dQPsCJ-t0-Gt",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe5f76d98ab6f1851b1222a619d68c5c",
     "grade": false,
     "grade_id": "cell-17278651b7e58ab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3c7SFZZJw6MU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1500be7e854dc4d11e9ab8ce40c44f4a",
     "grade": false,
     "grade_id": "cell-57bd2575631fb4c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set of all special characters\n",
    "sets_of_punctuations = set(string.punctuation)\n",
    "\n",
    "# Removing sets of all special characters from the inputs\n",
    "lines.eng = lines.eng.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))\n",
    "lines.chin = lines.chin.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zdfLmsrY0-Gt",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e6b1f4a051d2cb789b504fb6beb0685",
     "grade": false,
     "grade_id": "cell-5ae1b11f41d71b27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Removing Uneven Spaces\n",
    "#### Task 2\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "0NJg9Wtxw6MV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6262580c52c9c0d41e3f48056d849424",
     "grade": false,
     "grade_id": "cell-b5bd2c20a73d1679",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-2-Task-2\n",
    "# lines.eng = None\n",
    "# lines.chin = None\n",
    "\n",
    "# There may be uneven spaces in the inputs\n",
    "# We have to remove the extra spaces too\n",
    "\n",
    "# Exercise 2 | Task 2\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "lines[\"eng\"] = lines[\"eng\"].apply(lambda x:re.sub(\"\\s+\",\" \",x))\n",
    "lines[\"chin\"] = lines[\"chin\"].apply(lambda x:re.sub(\"\\s+\",\" \",x))\n",
    "\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "M4dMDkYn0-Gu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9274c3da54ce529a0a48fd322b407e24",
     "grade": true,
     "grade_id": "cell-557c50952c53e7ed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "assert lines.eng is not None\n",
    "assert lines.chin is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nf_nMZp00-Gu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50e043f4e44d400cb3a775b965b6b665",
     "grade": false,
     "grade_id": "cell-03607f2602068f04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Adding `<START>` and `<END>` Tokens\n",
    "E.g.\n",
    "'Hi' = '`<START>` Hi `<END>`'\n",
    "#### Task 3\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
    "We will perform this operations over Chinese column samples only because we are converting English sequences to chinese only for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "24kKSFCjw6MW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8df2bf22b3b379332eeeebc57bd287e",
     "grade": false,
     "grade_id": "cell-ad1abc3f8ffea62a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-3"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-2-Task-3\n",
    "# lines.chin = None\n",
    "\n",
    "# Adding <START> and <END> tokens with trailing spaces\n",
    "\n",
    "# Exercise 2 | Task 3\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "lines.chin = lines.chin.apply(lambda x: \"<START> \"+x+\" <END>\")\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PJA33kQZ0-Gu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a0a377fd98f6659655db1b424338212",
     "grade": true,
     "grade_id": "cell-fd254802897335ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-3"
    ]
   },
   "outputs": [],
   "source": [
    "assert lines.chin is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ojnbyezHqUaG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86a9ff8785d8ef6fb2437aae08cf171b",
     "grade": false,
     "grade_id": "cell-d4bdec9ded84970b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, our next task is to create a list of vocabularies of English and Chinese Inputs.\n",
    "\n",
    "Following code will tokenize the words present in the English and Chinese dataset that we use to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vBibz4Gn666N",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8153db3e15c212af999f9d8622e21efc",
     "grade": false,
     "grade_id": "cell-fd22ab95a6103221",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5GtJWhtG7UiM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31a8e3c3129bf64cf3af93c2d1e27ca2",
     "grade": false,
     "grade_id": "cell-3c2d3a9eb7586ce1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Tokenizing the English and the Chinese words in to set `all_english_vocabs` and `all_chinese_vocabs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dY-j6xPpqdPT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb09fd0d0113e567e720dff6a2d57257",
     "grade": false,
     "grade_id": "cell-cdb536778da0a35b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect English Vocabs\n",
    "all_english_vocabs = set()\n",
    "for english in lines.eng:\n",
    "    words = english.split()\n",
    "    for word in words:\n",
    "        if word not in all_english_vocabs:\n",
    "            all_english_vocabs.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UJGtunRdtPdX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c81f85aa3a4cd2c1d99800f0a4bfe4b",
     "grade": false,
     "grade_id": "cell-9573d55a6cc7a79a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect Chinese Vocabs\n",
    "all_chinese_vocabs = set()\n",
    "for chinese in lines.chin:\n",
    "    words = chinese.split()\n",
    "    for word in words:\n",
    "        if word not in all_chinese_vocabs:\n",
    "            all_chinese_vocabs.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AqQxd93At8Y_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aaa117a1a9ef6101a6dcbb4e172ff64c",
     "grade": false,
     "grade_id": "cell-2b285bbaaf0bb29c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's implement the following codes to find the maximum sequence length of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "ApMcilUdw6MX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8406af3f5b0446b0750be37157760ddf",
     "grade": false,
     "grade_id": "cell-54947cadd4bdeb58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "db604363-4b7e-4d04-d945-8410e118241d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Max Length of input sequence\n",
    "sequence_length = []\n",
    "for line in lines.eng:\n",
    "    sequence_length.append(len(line.split(' ')))\n",
    "max_length_inp = np.max(sequence_length)\n",
    "print(max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "5r8H-xriw6MX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4f46c3196a78a0d7abba9159251659",
     "grade": false,
     "grade_id": "cell-389126c8d63c4124",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2a97172e-966b-4720-e67c-25649d6a18f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of target sequence\n",
    "sequence_length = []\n",
    "for line in lines.chin:\n",
    "    sequence_length.append(len(line.split(' ')))\n",
    "max_length_targ = np.max(sequence_length)\n",
    "max_length_targ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "z2ID7e3a0-Gw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94d6bac02b2788a4fe011e9d500c21a4",
     "grade": false,
     "grade_id": "cell-8f6c8ab252764056",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With this, we can see that the maximum input sequence is 8 and the maximum target sequence is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "scApqmY00-Gw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d5094d209e6b7975b5e3eca73db2a9",
     "grade": false,
     "grade_id": "cell-05bfb2e9b479f1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "#### Task 1\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
    "Sort and store the tokenized English and Chinese words on the variables `input_words` and `target_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "id": "mTOotq_Iw6MY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9078779aa366ba1983eafb52d994367c",
     "grade": false,
     "grade_id": "cell-a233cc05cff264ec",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-3-Task-1\n",
    "\n",
    "# input_words = None\n",
    "# target_words = None\n",
    "\n",
    "# Sorting and Storing the tokens of English and Chinese words\n",
    "\n",
    "# Exercise 3\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "input_words = sorted(all_english_vocabs)\n",
    "target_words = sorted(all_chinese_vocabs)\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e9MTr3c-0-Gx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dc42d6bc240ed9b4598a698272bdbae",
     "grade": true,
     "grade_id": "cell-15b8c56f73279370",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert input_words is not None\n",
    "assert target_words is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlODcVXyAo98"
   },
   "source": [
    "#### Task 2\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
    "Since, we are performing Machine translation, we have an encoder and decoder kind of architecture. We will have the encoder architecture as following:\n",
    "\n",
    "<div align=\"center\">\n",
    "<figure>\n",
    "<img src=\"https://doc.google.com/a/fusemachines.com/uc?id=1voHxN0hllGSLfyPJSy6tI_hzTNO6hHRl\" >\n",
    "<figcaption>Figure 1. Machine Translation\n",
    "</figcaption>\n",
    "</figure>\n",
    "</div>\n",
    "\n",
    "Here, the green denoted LSTM cells represent the encoder part and the red LSTM cells represent the decoder part of a Machine Translation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "ZkXtWETvAnZ5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9db575d6fd33f6657706244f3d78c37",
     "grade": false,
     "grade_id": "cell-d21094fc3564a7c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "f2dac168-dd9b-480d-fe05-f79f78ca176a",
    "tags": [
     "Ex-3-Task-2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3380 9023\n"
     ]
    }
   ],
   "source": [
    "### Ex-3-Task-2\n",
    "# counting the total tokens of English and Chinese words\n",
    "num_encoder_tokens = None\n",
    "num_decoder_tokens = None\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION\n",
    "print(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RlmKrS1eQKpS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "HZSC0tsow6MY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be0bb5f1bd433ae49ce0865a36b5d4a3",
     "grade": false,
     "grade_id": "cell-040c48796e20c48e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "779d679a-364f-456b-bbc2-4274061d8544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3381, 9024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For zero padding we add one extra token\n",
    "num_decoder_tokens += 1\n",
    "num_encoder_tokens += 1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MYPMZqntw6MZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f9b24c88907af9d6fc4abfd0f2d3b26",
     "grade": false,
     "grade_id": "cell-df7be80213612242",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute and store the tokens with index in dictionary as word, index format\n",
    "input_token_index = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i + 1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ofUESFVWw6MZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe1c30203bafa9868d0d233747ebf40a",
     "grade": false,
     "grade_id": "cell-85cd917cd9596b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute and store the tokens with index in dictionary as index, word format\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "deletable": false,
    "editable": false,
    "id": "A-jl8mSpw6MZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4b730ef6492fbd05ede8bffededdea",
     "grade": false,
     "grade_id": "cell-75e847bed23fd5e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "f00b80dd-85d2-4b39-c466-d4f0c9a52f92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e0e12796-1c10-41ec-aeea-7ca6620f7164\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>chin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>get a grip on yourself</td>\n",
       "      <td>&lt;START&gt; 冷静下来！ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9217</th>\n",
       "      <td>toms name was on the list</td>\n",
       "      <td>&lt;START&gt; 湯姆的名字在名單上。 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>that river is long</td>\n",
       "      <td>&lt;START&gt; 那條河流很長。 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>i think tom is talented</td>\n",
       "      <td>&lt;START&gt; 我認為湯姆有才能。 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>we were born to die</td>\n",
       "      <td>&lt;START&gt; 我们是为了死亡而诞生的。 &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0e12796-1c10-41ec-aeea-7ca6620f7164')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e0e12796-1c10-41ec-aeea-7ca6620f7164 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e0e12796-1c10-41ec-aeea-7ca6620f7164');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                            eng                        chin\n",
       "5252     get a grip on yourself         <START> 冷静下来！ <END>\n",
       "9217  toms name was on the list    <START> 湯姆的名字在名單上。 <END>\n",
       "2969         that river is long       <START> 那條河流很長。 <END>\n",
       "6219    i think tom is talented     <START> 我認為湯姆有才能。 <END>\n",
       "3692        we were born to die  <START> 我们是为了死亡而诞生的。 <END>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the lines to make better predictions\n",
    "lines = shuffle(lines)\n",
    "lines.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ciFxeS0l0-Gy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e855f52ea26ed6a78b5271614a523804",
     "grade": false,
     "grade_id": "cell-4874858156792ac3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "U8-wDveew6Ma",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7eedfd692c48276f98708a8a8409bcd",
     "grade": false,
     "grade_id": "cell-711ad7496e8d5a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "a3cc71bc-e9c1-47ff-fdc4-c83110dd962b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000,), (1000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng, lines.chin\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zSVXqHNaLirV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7857b81bc963cfe85ff7a67874257c74",
     "grade": false,
     "grade_id": "cell-9456558d54c0d0ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Following code is to generate batch of training and testing data. If you are interested in the code you can go line by line and explore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kM-5q9lbw6Ma",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d776a860adbff380724704f73503def3",
     "grade": false,
     "grade_id": "cell-b1894cc022235615",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    '''Function to generate a batch of data '''\n",
    "    for j in range(0, len(X), batch_size):\n",
    "        encoder_input_data = np.zeros((max_length_inp, batch_size),dtype='float32')\n",
    "        decoder_input_data = np.zeros((max_length_targ, batch_size),dtype='float32')\n",
    "        decoder_target_data = np.zeros((max_length_targ, batch_size ,num_decoder_tokens),dtype='float32')\n",
    "        for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "            for t, word in enumerate(input_text.split()):\n",
    "                encoder_input_data[t, i] = input_token_index[word] # encoder input seq\n",
    "            for t, word in enumerate(target_text.split()):\n",
    "                if t<len(target_text.split())-1:\n",
    "                    decoder_input_data[t, i] = target_token_index[word] # decoder input seq\n",
    "                if t>0:\n",
    "                    # decoder target sequence (one hot encoded)\n",
    "                    # does not include the START_ token\n",
    "                    # Offset by one timestep\n",
    "                    decoder_target_data[t-1, i , target_token_index[word]] = 1.\n",
    "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VrCmUOPX0dsn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "108ad531aae4affa988fcf9dbb1216f5",
     "grade": false,
     "grade_id": "cell-5ad4b7a3cc4da9e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Input to the Encoder\n",
    "encoder_input_data = np.zeros((len(lines.eng), 9),dtype='float32')\n",
    "\n",
    "# output from the encoder or input to the decoder\n",
    "decoder_input_data = np.zeros((len(lines.chin), 5),dtype='float32')\n",
    "\n",
    "# output by the decoder\n",
    "decoder_target_data = np.zeros((len(lines.chin), 5, num_decoder_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "z3QkOfY70hQK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dd8a7bcec06c4a8c969cf1ef6c956b0",
     "grade": false,
     "grade_id": "cell-3c9e2cbc956e1e63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.chin)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder target data is ahead of decoder input by one timestep\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aknXbSOLw6Mb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1acb35327047493c41527dbd89cd048",
     "grade": false,
     "grade_id": "cell-dbc8da1b20dbba17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7Wd_xqIbw6Mb",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eab08df97a955b75b73b334158d24f58",
     "grade": false,
     "grade_id": "cell-6e9227c55dc44051",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BSPvU8Bn0-G0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d20248101d130edfd111600d207cd56",
     "grade": false,
     "grade_id": "cell-906a013f79181247",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4\n",
    "<b><div style=\"text-align: right\">[POINTS: 4]</div></b>\n",
    "#### Task 1\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
    "Store the hidden state and context vector as a result of encoder outputs on variable `encoder_states`.\n",
    "\n",
    "Store in the form of [__hiddenstate__, __contextstate__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "id": "i5U5W2T9f7Qk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63deee770ecdaabe4190ed7e5abe4859",
     "grade": false,
     "grade_id": "cell-5375e524cb9be57b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-4-Task-1\n",
    "# encoder_states = None\n",
    "\n",
    "# Encoder Architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        # your code here\n",
    "        encoder_states = [hidden_state,cell_state]\n",
    "        # raise NotImplementedError\n",
    "        ### END SOLUTION\n",
    "        return encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sk67U0fRx212",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aa9b3af095f8429833dca9530395f81",
     "grade": true,
     "grade_id": "cell-71c476202d589f78",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally left blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "-miqEPX4f7Ql",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78b937a268a0f394a91de96f76b3a5e9",
     "grade": false,
     "grade_id": "cell-ddac4c4be3f9b645",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "d881b28a-5f09-4449-e626-c66ee3efd445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(3381, 50)\n",
      "  (LSTM): LSTM(50, 50)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(num_encoder_tokens, latent_dim, latent_dim)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jwgWEUvqf7Qm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3763687430eae58b6cbbcb7e65d2c712",
     "grade": false,
     "grade_id": "cell-57a28a9db81414dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # Size of the one hot vectors that will be the input to the decoder\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Output size of the word embedding NN\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Size of the one hot vectors that will be the output of the decoder\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, enc_states):\n",
    "        x = x.unsqueeze(0)\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # (passing encoder's hs, cs - context vectors)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, enc_states)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        decoder_states = (hidden_state, cell_state)\n",
    "\n",
    "        return predictions, decoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "zuqq79h6f7Qm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f14fa8d3ff8a10b6287be85df6c77281",
     "grade": false,
     "grade_id": "cell-5f7f0bed03f209a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "232aee75-7d88-45fd-e6f6-35659d306e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(9024, 50)\n",
      "  (LSTM): LSTM(50, 50)\n",
      "  (fc): Linear(in_features=50, out_features=9024, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ycS6r5fkf7Qm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "212805f25732ea0776a6ce3bd0a57458",
     "grade": false,
     "grade_id": "cell-c8fc9c2ef2ac84be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.Encoder_LSTM = Encoder_LSTM\n",
    "        self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "    def forward(self, source, target, tfr=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = num_decoder_tokens\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "\n",
    "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
    "\n",
    "        x = target[0]\n",
    "\n",
    "        for i in range(1, target_len):\n",
    "            output, ( hidden_state, cell_state ) = self.Decoder_LSTM(x, (hidden_state, cell_state))\n",
    "            outputs[i] = output\n",
    "            best_guess = output.argmax(1) # 1st dimension is word embedding, 0th dimension is batchsize\n",
    "            x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KxU_HH2mf7Qm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c324a3bc939ea45333ebc3d6435cbf34",
     "grade": false,
     "grade_id": "cell-61d8cb7f520b0326",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "step = 0\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xu-3m5qg0-G1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07abc23b4cedabba832b7e15d98d3fef",
     "grade": false,
     "grade_id": "cell-cdd4235d80801b39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Task 2\n",
    "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
    "Increase the number of epochs and train the model to obtain a good accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cymSsIYQw6Me",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a67eb038486a9db3fc03603d8b6ed6",
     "grade": false,
     "grade_id": "cell-d5ca1a01a0838cda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Some model hyperparameters\n",
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 256\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "ZWX1460-zVv6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1506343e4b40cdd6ca2faf2b9c5c3923",
     "grade": false,
     "grade_id": "cell-9fdc16b573193e9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "182b4b3b-33e9-48c1-d2a7-d24f157bbca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 / 10\n",
      "Iterations / loss -  0 / 9.072749137878418\n",
      "\n",
      "Iterations / loss -  1 / 9.026429176330566\n",
      "\n",
      "Iterations / loss -  2 / 8.985509872436523\n",
      "\n",
      "Iterations / loss -  3 / 8.939216613769531\n",
      "\n",
      "Iterations / loss -  4 / 8.88586711883545\n",
      "\n",
      "Iterations / loss -  5 / 8.828453063964844\n",
      "\n",
      "Iterations / loss -  6 / 8.797380447387695\n",
      "\n",
      "Iterations / loss -  7 / 8.663753509521484\n",
      "\n",
      "Iterations / loss -  8 / 8.666975975036621\n",
      "\n",
      "Iterations / loss -  9 / 8.564804077148438\n",
      "\n",
      "Iterations / loss -  10 / 8.442745208740234\n",
      "\n",
      "Iterations / loss -  11 / 8.369649887084961\n",
      "\n",
      "Iterations / loss -  12 / 8.267593383789062\n",
      "\n",
      "Iterations / loss -  13 / 8.159355163574219\n",
      "\n",
      "Iterations / loss -  14 / 8.066217422485352\n",
      "\n",
      "Iterations / loss -  15 / 7.958845615386963\n",
      "\n",
      "Iterations / loss -  16 / 7.827176570892334\n",
      "\n",
      "Iterations / loss -  17 / 7.726943492889404\n",
      "\n",
      "Iterations / loss -  18 / 7.59357213973999\n",
      "\n",
      "Iterations / loss -  19 / 7.455556869506836\n",
      "\n",
      "Iterations / loss -  20 / 7.335023880004883\n",
      "\n",
      "Iterations / loss -  21 / 7.192366123199463\n",
      "\n",
      "Iterations / loss -  22 / 7.061967372894287\n",
      "\n",
      "Iterations / loss -  23 / 6.914247035980225\n",
      "\n",
      "Iterations / loss -  24 / 6.767022132873535\n",
      "\n",
      "Iterations / loss -  25 / 6.618657112121582\n",
      "\n",
      "Iterations / loss -  26 / 6.457664966583252\n",
      "\n",
      "Iterations / loss -  27 / 6.31676721572876\n",
      "\n",
      "Iterations / loss -  28 / 6.131634712219238\n",
      "\n",
      "Iterations / loss -  29 / 5.9812140464782715\n",
      "\n",
      "Iterations / loss -  30 / 5.829857349395752\n",
      "\n",
      "Iterations / loss -  31 / 5.666250228881836\n",
      "\n",
      "Iterations / loss -  32 / 5.505460739135742\n",
      "\n",
      "Iterations / loss -  33 / 5.335503578186035\n",
      "\n",
      "Iterations / loss -  34 / 5.17656946182251\n",
      "\n",
      "Iterations / loss -  35 / 5.292930603027344\n",
      "\n",
      "Epoch - 2 / 10\n",
      "Iterations / loss -  0 / 4.854396343231201\n",
      "\n",
      "Iterations / loss -  1 / 4.682854652404785\n",
      "\n",
      "Iterations / loss -  2 / 4.5327301025390625\n",
      "\n",
      "Iterations / loss -  3 / 4.358794212341309\n",
      "\n",
      "Iterations / loss -  4 / 4.213608264923096\n",
      "\n",
      "Iterations / loss -  5 / 4.042374134063721\n",
      "\n",
      "Iterations / loss -  6 / 3.8951635360717773\n",
      "\n",
      "Iterations / loss -  7 / 3.714543581008911\n",
      "\n",
      "Iterations / loss -  8 / 3.558767318725586\n",
      "\n",
      "Iterations / loss -  9 / 3.3948004245758057\n",
      "\n",
      "Iterations / loss -  10 / 3.2539353370666504\n",
      "\n",
      "Iterations / loss -  11 / 3.1059117317199707\n",
      "\n",
      "Iterations / loss -  12 / 2.9653384685516357\n",
      "\n",
      "Iterations / loss -  13 / 2.8018641471862793\n",
      "\n",
      "Iterations / loss -  14 / 2.661041736602783\n",
      "\n",
      "Iterations / loss -  15 / 2.523336410522461\n",
      "\n",
      "Iterations / loss -  16 / 2.368778944015503\n",
      "\n",
      "Iterations / loss -  17 / 2.2364776134490967\n",
      "\n",
      "Iterations / loss -  18 / 2.102905511856079\n",
      "\n",
      "Iterations / loss -  19 / 1.9737945795059204\n",
      "\n",
      "Iterations / loss -  20 / 1.8568974733352661\n",
      "\n",
      "Iterations / loss -  21 / 1.7489330768585205\n",
      "\n",
      "Iterations / loss -  22 / 1.6365946531295776\n",
      "\n",
      "Iterations / loss -  23 / 1.5227949619293213\n",
      "\n",
      "Iterations / loss -  24 / 1.4388470649719238\n",
      "\n",
      "Iterations / loss -  25 / 1.3366272449493408\n",
      "\n",
      "Iterations / loss -  26 / 1.244385004043579\n",
      "\n",
      "Iterations / loss -  27 / 1.1621341705322266\n",
      "\n",
      "Iterations / loss -  28 / 1.0718220472335815\n",
      "\n",
      "Iterations / loss -  29 / 1.0035239458084106\n",
      "\n",
      "Iterations / loss -  30 / 0.9324973225593567\n",
      "\n",
      "Iterations / loss -  31 / 0.8629395961761475\n",
      "\n",
      "Iterations / loss -  32 / 0.8045466542243958\n",
      "\n",
      "Iterations / loss -  33 / 0.7492354512214661\n",
      "\n",
      "Iterations / loss -  34 / 0.7163086533546448\n",
      "\n",
      "Iterations / loss -  35 / 1.517998218536377\n",
      "\n",
      "Epoch - 3 / 10\n",
      "Iterations / loss -  0 / 0.618657648563385\n",
      "\n",
      "Iterations / loss -  1 / 0.5693804621696472\n",
      "\n",
      "Iterations / loss -  2 / 0.5360090136528015\n",
      "\n",
      "Iterations / loss -  3 / 0.5088034272193909\n",
      "\n",
      "Iterations / loss -  4 / 0.4733342230319977\n",
      "\n",
      "Iterations / loss -  5 / 0.4434143900871277\n",
      "\n",
      "Iterations / loss -  6 / 0.42884838581085205\n",
      "\n",
      "Iterations / loss -  7 / 0.3942095935344696\n",
      "\n",
      "Iterations / loss -  8 / 0.3746925890445709\n",
      "\n",
      "Iterations / loss -  9 / 0.3508378565311432\n",
      "\n",
      "Iterations / loss -  10 / 0.340143620967865\n",
      "\n",
      "Iterations / loss -  11 / 0.3240663707256317\n",
      "\n",
      "Iterations / loss -  12 / 0.3189048767089844\n",
      "\n",
      "Iterations / loss -  13 / 0.29161566495895386\n",
      "\n",
      "Iterations / loss -  14 / 0.28292709589004517\n",
      "\n",
      "Iterations / loss -  15 / 0.2748207151889801\n",
      "\n",
      "Iterations / loss -  16 / 0.2427985668182373\n",
      "\n",
      "Iterations / loss -  17 / 0.23297426104545593\n",
      "\n",
      "Iterations / loss -  18 / 0.22254131734371185\n",
      "\n",
      "Iterations / loss -  19 / 0.2130376696586609\n",
      "\n",
      "Iterations / loss -  20 / 0.20447735488414764\n",
      "\n",
      "Iterations / loss -  21 / 0.20586547255516052\n",
      "\n",
      "Iterations / loss -  22 / 0.1980299949645996\n",
      "\n",
      "Iterations / loss -  23 / 0.1816171109676361\n",
      "\n",
      "Iterations / loss -  24 / 0.1969088315963745\n",
      "\n",
      "Iterations / loss -  25 / 0.18250420689582825\n",
      "\n",
      "Iterations / loss -  26 / 0.17335720360279083\n",
      "\n",
      "Iterations / loss -  27 / 0.17112424969673157\n",
      "\n",
      "Iterations / loss -  28 / 0.15516889095306396\n",
      "\n",
      "Iterations / loss -  29 / 0.1613132357597351\n",
      "\n",
      "Iterations / loss -  30 / 0.14684121310710907\n",
      "\n",
      "Iterations / loss -  31 / 0.14131636917591095\n",
      "\n",
      "Iterations / loss -  32 / 0.13816994428634644\n",
      "\n",
      "Iterations / loss -  33 / 0.13467362523078918\n",
      "\n",
      "Iterations / loss -  34 / 0.15787619352340698\n",
      "\n",
      "Iterations / loss -  35 / 1.1514161825180054\n",
      "\n",
      "Epoch - 4 / 10\n",
      "Iterations / loss -  0 / 0.13566382229328156\n",
      "\n",
      "Iterations / loss -  1 / 0.12294591218233109\n",
      "\n",
      "Iterations / loss -  2 / 0.12146149575710297\n",
      "\n",
      "Iterations / loss -  3 / 0.12815430760383606\n",
      "\n",
      "Iterations / loss -  4 / 0.11704616248607635\n",
      "\n",
      "Iterations / loss -  5 / 0.11464647203683853\n",
      "\n",
      "Iterations / loss -  6 / 0.12263163924217224\n",
      "\n",
      "Iterations / loss -  7 / 0.11207489669322968\n",
      "\n",
      "Iterations / loss -  8 / 0.11070922017097473\n",
      "\n",
      "Iterations / loss -  9 / 0.10779938846826553\n",
      "\n",
      "Iterations / loss -  10 / 0.11739195883274078\n",
      "\n",
      "Iterations / loss -  11 / 0.11402605473995209\n",
      "\n",
      "Iterations / loss -  12 / 0.12355940043926239\n",
      "\n",
      "Iterations / loss -  13 / 0.11371269077062607\n",
      "\n",
      "Iterations / loss -  14 / 0.11110137403011322\n",
      "\n",
      "Iterations / loss -  15 / 0.11727970838546753\n",
      "\n",
      "Iterations / loss -  16 / 0.09551585465669632\n",
      "\n",
      "Iterations / loss -  17 / 0.0950026884675026\n",
      "\n",
      "Iterations / loss -  18 / 0.09391289949417114\n",
      "\n",
      "Iterations / loss -  19 / 0.09247642010450363\n",
      "\n",
      "Iterations / loss -  20 / 0.09152401238679886\n",
      "\n",
      "Iterations / loss -  21 / 0.0995490625500679\n",
      "\n",
      "Iterations / loss -  22 / 0.10055916011333466\n",
      "\n",
      "Iterations / loss -  23 / 0.08651313185691833\n",
      "\n",
      "Iterations / loss -  24 / 0.10781548172235489\n",
      "\n",
      "Iterations / loss -  25 / 0.09742652624845505\n",
      "\n",
      "Iterations / loss -  26 / 0.09552214294672012\n",
      "\n",
      "Iterations / loss -  27 / 0.0943613350391388\n",
      "\n",
      "Iterations / loss -  28 / 0.08173012733459473\n",
      "\n",
      "Iterations / loss -  29 / 0.08929824829101562\n",
      "\n",
      "Iterations / loss -  30 / 0.07898060232400894\n",
      "\n",
      "Iterations / loss -  31 / 0.07705840468406677\n",
      "\n",
      "Iterations / loss -  32 / 0.07651229947805405\n",
      "\n",
      "Iterations / loss -  33 / 0.07526417821645737\n",
      "\n",
      "Iterations / loss -  34 / 0.09698371589183807\n",
      "\n",
      "Iterations / loss -  35 / 0.666297197341919\n",
      "\n",
      "Epoch - 5 / 10\n",
      "Iterations / loss -  0 / 0.08526968955993652\n",
      "\n",
      "Iterations / loss -  1 / 0.07233494520187378\n",
      "\n",
      "Iterations / loss -  2 / 0.07248751074075699\n",
      "\n",
      "Iterations / loss -  3 / 0.08085034042596817\n",
      "\n",
      "Iterations / loss -  4 / 0.07066541165113449\n",
      "\n",
      "Iterations / loss -  5 / 0.0698222890496254\n",
      "\n",
      "Iterations / loss -  6 / 0.07954122871160507\n",
      "\n",
      "Iterations / loss -  7 / 0.06973066926002502\n",
      "\n",
      "Iterations / loss -  8 / 0.06892365962266922\n",
      "\n",
      "Iterations / loss -  9 / 0.06775492429733276\n",
      "\n",
      "Iterations / loss -  10 / 0.07885254174470901\n",
      "\n",
      "Iterations / loss -  11 / 0.07606685906648636\n",
      "\n",
      "Iterations / loss -  12 / 0.08599115908145905\n",
      "\n",
      "Iterations / loss -  13 / 0.07798268646001816\n",
      "\n",
      "Iterations / loss -  14 / 0.07876989990472794\n",
      "\n",
      "Iterations / loss -  15 / 0.08331069350242615\n",
      "\n",
      "Iterations / loss -  16 / 0.06224949285387993\n",
      "\n",
      "Iterations / loss -  17 / 0.0622761994600296\n",
      "\n",
      "Iterations / loss -  18 / 0.062048446387052536\n",
      "\n",
      "Iterations / loss -  19 / 0.06140274927020073\n",
      "\n",
      "Iterations / loss -  20 / 0.06131991744041443\n",
      "\n",
      "Iterations / loss -  21 / 0.0702008381485939\n",
      "\n",
      "Iterations / loss -  22 / 0.06964591890573502\n",
      "\n",
      "Iterations / loss -  23 / 0.058621473610401154\n",
      "\n",
      "Iterations / loss -  24 / 0.08068934082984924\n",
      "\n",
      "Iterations / loss -  25 / 0.07113392651081085\n",
      "\n",
      "Iterations / loss -  26 / 0.06673913449048996\n",
      "\n",
      "Iterations / loss -  27 / 0.06619857251644135\n",
      "\n",
      "Iterations / loss -  28 / 0.05675993114709854\n",
      "\n",
      "Iterations / loss -  29 / 0.06506884098052979\n",
      "\n",
      "Iterations / loss -  30 / 0.05500403791666031\n",
      "\n",
      "Iterations / loss -  31 / 0.05387383699417114\n",
      "\n",
      "Iterations / loss -  32 / 0.05378943309187889\n",
      "\n",
      "Iterations / loss -  33 / 0.05296763405203819\n",
      "\n",
      "Iterations / loss -  34 / 0.07503656297922134\n",
      "\n",
      "Iterations / loss -  35 / 0.8336765766143799\n",
      "\n",
      "Epoch - 6 / 10\n",
      "Iterations / loss -  0 / 0.06460074335336685\n",
      "\n",
      "Iterations / loss -  1 / 0.05183509737253189\n",
      "\n",
      "Iterations / loss -  2 / 0.052365340292453766\n",
      "\n",
      "Iterations / loss -  3 / 0.06475215405225754\n",
      "\n",
      "Iterations / loss -  4 / 0.05134151503443718\n",
      "\n",
      "Iterations / loss -  5 / 0.0510682575404644\n",
      "\n",
      "Iterations / loss -  6 / 0.06496778875589371\n",
      "\n",
      "Iterations / loss -  7 / 0.052104175090789795\n",
      "\n",
      "Iterations / loss -  8 / 0.051422636955976486\n",
      "\n",
      "Iterations / loss -  9 / 0.050811294466257095\n",
      "\n",
      "Iterations / loss -  10 / 0.05944651737809181\n",
      "\n",
      "Iterations / loss -  11 / 0.06306170672178268\n",
      "\n",
      "Iterations / loss -  12 / 0.06973358988761902\n",
      "\n",
      "Iterations / loss -  13 / 0.06266514211893082\n",
      "\n",
      "Iterations / loss -  14 / 0.06369952112436295\n",
      "\n",
      "Iterations / loss -  15 / 0.06812624633312225\n",
      "\n",
      "Iterations / loss -  16 / 0.04715792089700699\n",
      "\n",
      "Iterations / loss -  17 / 0.04753168299794197\n",
      "\n",
      "Iterations / loss -  18 / 0.047679100185632706\n",
      "\n",
      "Iterations / loss -  19 / 0.04720817878842354\n",
      "\n",
      "Iterations / loss -  20 / 0.04736439138650894\n",
      "\n",
      "Iterations / loss -  21 / 0.059950679540634155\n",
      "\n",
      "Iterations / loss -  22 / 0.059134673327207565\n",
      "\n",
      "Iterations / loss -  23 / 0.04519633203744888\n",
      "\n",
      "Iterations / loss -  24 / 0.06406977772712708\n",
      "\n",
      "Iterations / loss -  25 / 0.054720181971788406\n",
      "\n",
      "Iterations / loss -  26 / 0.05729847773909569\n",
      "\n",
      "Iterations / loss -  27 / 0.053286463022232056\n",
      "\n",
      "Iterations / loss -  28 / 0.044275008141994476\n",
      "\n",
      "Iterations / loss -  29 / 0.052580274641513824\n",
      "\n",
      "Iterations / loss -  30 / 0.04252473637461662\n",
      "\n",
      "Iterations / loss -  31 / 0.04174775630235672\n",
      "\n",
      "Iterations / loss -  32 / 0.041773051023483276\n",
      "\n",
      "Iterations / loss -  33 / 0.04098667576909065\n",
      "\n",
      "Iterations / loss -  34 / 0.06984004378318787\n",
      "\n",
      "Iterations / loss -  35 / 0.47249290347099304\n",
      "\n",
      "Epoch - 7 / 10\n",
      "Iterations / loss -  0 / 0.053243428468704224\n",
      "\n",
      "Iterations / loss -  1 / 0.04035254195332527\n",
      "\n",
      "Iterations / loss -  2 / 0.040738001465797424\n",
      "\n",
      "Iterations / loss -  3 / 0.049862246960401535\n",
      "\n",
      "Iterations / loss -  4 / 0.03979811817407608\n",
      "\n",
      "Iterations / loss -  5 / 0.0394987091422081\n",
      "\n",
      "Iterations / loss -  6 / 0.053777627646923065\n",
      "\n",
      "Iterations / loss -  7 / 0.04022814705967903\n",
      "\n",
      "Iterations / loss -  8 / 0.039580583572387695\n",
      "\n",
      "Iterations / loss -  9 / 0.03931483253836632\n",
      "\n",
      "Iterations / loss -  10 / 0.05125250667333603\n",
      "\n",
      "Iterations / loss -  11 / 0.0483836904168129\n",
      "\n",
      "Iterations / loss -  12 / 0.062164075672626495\n",
      "\n",
      "Iterations / loss -  13 / 0.05160015448927879\n",
      "\n",
      "Iterations / loss -  14 / 0.04887828603386879\n",
      "\n",
      "Iterations / loss -  15 / 0.06275930255651474\n",
      "\n",
      "Iterations / loss -  16 / 0.03662025183439255\n",
      "\n",
      "Iterations / loss -  17 / 0.036793071776628494\n",
      "\n",
      "Iterations / loss -  18 / 0.036941491067409515\n",
      "\n",
      "Iterations / loss -  19 / 0.03656653314828873\n",
      "\n",
      "Iterations / loss -  20 / 0.03678049147129059\n",
      "\n",
      "Iterations / loss -  21 / 0.049957942217588425\n",
      "\n",
      "Iterations / loss -  22 / 0.046006493270397186\n",
      "\n",
      "Iterations / loss -  23 / 0.03542093187570572\n",
      "\n",
      "Iterations / loss -  24 / 0.05435658618807793\n",
      "\n",
      "Iterations / loss -  25 / 0.04904207959771156\n",
      "\n",
      "Iterations / loss -  26 / 0.04454028233885765\n",
      "\n",
      "Iterations / loss -  27 / 0.0442153736948967\n",
      "\n",
      "Iterations / loss -  28 / 0.03504209965467453\n",
      "\n",
      "Iterations / loss -  29 / 0.04353558272123337\n",
      "\n",
      "Iterations / loss -  30 / 0.03372358903288841\n",
      "\n",
      "Iterations / loss -  31 / 0.03325345739722252\n",
      "\n",
      "Iterations / loss -  32 / 0.03335282579064369\n",
      "\n",
      "Iterations / loss -  33 / 0.032758548855781555\n",
      "\n",
      "Iterations / loss -  34 / 0.061790402978658676\n",
      "\n",
      "Iterations / loss -  35 / 0.4279415011405945\n",
      "\n",
      "Epoch - 8 / 10\n",
      "Iterations / loss -  0 / 0.04197200760245323\n",
      "\n",
      "Iterations / loss -  1 / 0.03244756534695625\n",
      "\n",
      "Iterations / loss -  2 / 0.03276097774505615\n",
      "\n",
      "Iterations / loss -  3 / 0.04214150086045265\n",
      "\n",
      "Iterations / loss -  4 / 0.032132744789123535\n",
      "\n",
      "Iterations / loss -  5 / 0.03191952407360077\n",
      "\n",
      "Iterations / loss -  6 / 0.04262538254261017\n",
      "\n",
      "Iterations / loss -  7 / 0.03271498158574104\n",
      "\n",
      "Iterations / loss -  8 / 0.032188791781663895\n",
      "\n",
      "Iterations / loss -  9 / 0.03209991008043289\n",
      "\n",
      "Iterations / loss -  10 / 0.040729932487010956\n",
      "\n",
      "Iterations / loss -  11 / 0.041298434138298035\n",
      "\n",
      "Iterations / loss -  12 / 0.051359035074710846\n",
      "\n",
      "Iterations / loss -  13 / 0.0410471074283123\n",
      "\n",
      "Iterations / loss -  14 / 0.04587141424417496\n",
      "\n",
      "Iterations / loss -  15 / 0.05627954751253128\n",
      "\n",
      "Iterations / loss -  16 / 0.030060671269893646\n",
      "\n",
      "Iterations / loss -  17 / 0.030230725184082985\n",
      "\n",
      "Iterations / loss -  18 / 0.030476700514554977\n",
      "\n",
      "Iterations / loss -  19 / 0.030144641175866127\n",
      "\n",
      "Iterations / loss -  20 / 0.030414734035730362\n",
      "\n",
      "Iterations / loss -  21 / 0.03980918228626251\n",
      "\n",
      "Iterations / loss -  22 / 0.03973855823278427\n",
      "\n",
      "Iterations / loss -  23 / 0.029342694208025932\n",
      "\n",
      "Iterations / loss -  24 / 0.05287589877843857\n",
      "\n",
      "Iterations / loss -  25 / 0.039168570190668106\n",
      "\n",
      "Iterations / loss -  26 / 0.04250217229127884\n",
      "\n",
      "Iterations / loss -  27 / 0.03832334280014038\n",
      "\n",
      "Iterations / loss -  28 / 0.02922455593943596\n",
      "\n",
      "Iterations / loss -  29 / 0.0416690967977047\n",
      "\n",
      "Iterations / loss -  30 / 0.02796921133995056\n",
      "\n",
      "Iterations / loss -  31 / 0.02767334319651127\n",
      "\n",
      "Iterations / loss -  32 / 0.02777806855738163\n",
      "\n",
      "Iterations / loss -  33 / 0.02723970077931881\n",
      "\n",
      "Iterations / loss -  34 / 0.0564805269241333\n",
      "\n",
      "Iterations / loss -  35 / 0.6139543652534485\n",
      "\n",
      "Epoch - 9 / 10\n",
      "Iterations / loss -  0 / 0.04025821387767792\n",
      "\n",
      "Iterations / loss -  1 / 0.027309076860547066\n",
      "\n",
      "Iterations / loss -  2 / 0.02779749222099781\n",
      "\n",
      "Iterations / loss -  3 / 0.04132922366261482\n",
      "\n",
      "Iterations / loss -  4 / 0.027421532198786736\n",
      "\n",
      "Iterations / loss -  5 / 0.02744443155825138\n",
      "\n",
      "Iterations / loss -  6 / 0.042667921632528305\n",
      "\n",
      "Iterations / loss -  7 / 0.02911335788667202\n",
      "\n",
      "Iterations / loss -  8 / 0.02854112721979618\n",
      "\n",
      "Iterations / loss -  9 / 0.028556469827890396\n",
      "\n",
      "Iterations / loss -  10 / 0.03693842887878418\n",
      "\n",
      "Iterations / loss -  11 / 0.03764135017991066\n",
      "\n",
      "Iterations / loss -  12 / 0.05167941376566887\n",
      "\n",
      "Iterations / loss -  13 / 0.03763432428240776\n",
      "\n",
      "Iterations / loss -  14 / 0.043044526129961014\n",
      "\n",
      "Iterations / loss -  15 / 0.05300889536738396\n",
      "\n",
      "Iterations / loss -  16 / 0.026422519236803055\n",
      "\n",
      "Iterations / loss -  17 / 0.02687118574976921\n",
      "\n",
      "Iterations / loss -  18 / 0.02740086056292057\n",
      "\n",
      "Iterations / loss -  19 / 0.02682831883430481\n",
      "\n",
      "Iterations / loss -  20 / 0.02747359313070774\n",
      "\n",
      "Iterations / loss -  21 / 0.040637630969285965\n",
      "\n",
      "Iterations / loss -  22 / 0.036321885883808136\n",
      "\n",
      "Iterations / loss -  23 / 0.026100438088178635\n",
      "\n",
      "Iterations / loss -  24 / 0.04833525791764259\n",
      "\n",
      "Iterations / loss -  25 / 0.0400766022503376\n",
      "\n",
      "Iterations / loss -  26 / 0.039187658578157425\n",
      "\n",
      "Iterations / loss -  27 / 0.03473630174994469\n",
      "\n",
      "Iterations / loss -  28 / 0.026181915774941444\n",
      "\n",
      "Iterations / loss -  29 / 0.03833836689591408\n",
      "\n",
      "Iterations / loss -  30 / 0.024473687633872032\n",
      "\n",
      "Iterations / loss -  31 / 0.024355243891477585\n",
      "\n",
      "Iterations / loss -  32 / 0.024463925510644913\n",
      "\n",
      "Iterations / loss -  33 / 0.023696716874837875\n",
      "\n",
      "Iterations / loss -  34 / 0.05323482304811478\n",
      "\n",
      "Iterations / loss -  35 / 0.3800222873687744\n",
      "\n",
      "Epoch - 10 / 10\n",
      "Iterations / loss -  0 / 0.03686792775988579\n",
      "\n",
      "Iterations / loss -  1 / 0.02384045161306858\n",
      "\n",
      "Iterations / loss -  2 / 0.02424520067870617\n",
      "\n",
      "Iterations / loss -  3 / 0.03793271258473396\n",
      "\n",
      "Iterations / loss -  4 / 0.023755725473165512\n",
      "\n",
      "Iterations / loss -  5 / 0.023701904341578484\n",
      "\n",
      "Iterations / loss -  6 / 0.03916214406490326\n",
      "\n",
      "Iterations / loss -  7 / 0.025033453479409218\n",
      "\n",
      "Iterations / loss -  8 / 0.024515120312571526\n",
      "\n",
      "Iterations / loss -  9 / 0.024492982774972916\n",
      "\n",
      "Iterations / loss -  10 / 0.03270401060581207\n",
      "\n",
      "Iterations / loss -  11 / 0.03787359222769737\n",
      "\n",
      "Iterations / loss -  12 / 0.04779434576630592\n",
      "\n",
      "Iterations / loss -  13 / 0.03339407965540886\n",
      "\n",
      "Iterations / loss -  14 / 0.034455493092536926\n",
      "\n",
      "Iterations / loss -  15 / 0.04289734736084938\n",
      "\n",
      "Iterations / loss -  16 / 0.022399310022592545\n",
      "\n",
      "Iterations / loss -  17 / 0.022701917216181755\n",
      "\n",
      "Iterations / loss -  18 / 0.023126551881432533\n",
      "\n",
      "Iterations / loss -  19 / 0.022628378123044968\n",
      "\n",
      "Iterations / loss -  20 / 0.023097580298781395\n",
      "\n",
      "Iterations / loss -  21 / 0.03229155018925667\n",
      "\n",
      "Iterations / loss -  22 / 0.03219626471400261\n",
      "\n",
      "Iterations / loss -  23 / 0.022186266258358955\n",
      "\n",
      "Iterations / loss -  24 / 0.04473964869976044\n",
      "\n",
      "Iterations / loss -  25 / 0.03641844540834427\n",
      "\n",
      "Iterations / loss -  26 / 0.03562694042921066\n",
      "\n",
      "Iterations / loss -  27 / 0.03558862581849098\n",
      "\n",
      "Iterations / loss -  28 / 0.022234763950109482\n",
      "\n",
      "Iterations / loss -  29 / 0.03480488434433937\n",
      "\n",
      "Iterations / loss -  30 / 0.02094798907637596\n",
      "\n",
      "Iterations / loss -  31 / 0.020969456061720848\n",
      "\n",
      "Iterations / loss -  32 / 0.021100152283906937\n",
      "\n",
      "Iterations / loss -  33 / 0.020440800115466118\n",
      "\n",
      "Iterations / loss -  34 / 0.04149432107806206\n",
      "\n",
      "Iterations / loss -  35 / 0.302674263715744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epoch_loss = 0.0\n",
    "best_loss = 999999\n",
    "losses = []\n",
    "best_epoch = -1\n",
    "ts1  = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_list = []\n",
    "    print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "\n",
    "\n",
    "    model.train(True)\n",
    "    for batch_idx, ( input_data, target_data ) in enumerate(generate_batch(batch_size=batch_size)):\n",
    "        input_data_enc = torch.tensor(input_data[0]).long()\n",
    "        input_data_dec = torch.tensor(input_data[1]).long()\n",
    "        target = torch.tensor(target_data.argmax(2)).long()\n",
    "\n",
    "        # Pass the input and target for model's forward method\n",
    "        output = model(input_data_enc, target)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        # Clear the accumulating gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate the loss value for every epoch\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Calculate the gradients for weights & biases using back-propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights values using the gradients we calculated using bp\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss_list.append(loss.item())\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "        if ((epoch - best_epoch) >= 10):\n",
    "            print(\"no improvement in 10 epochs, break\")\n",
    "            break\n",
    "        print(\"Iterations / loss -  {} / {}\".format(batch_idx,loss.item()))\n",
    "        print()\n",
    "    losses.append(np.mean(epoch_loss_list))\n",
    "\n",
    "torch.save({\n",
    "          'model_state_dict': model.state_dict(),\n",
    "          'loss': losses\n",
    "          },\"lstm_seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "id": "K1kgspYr0-G1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a606c7517aefd327f82ecdc8c1e0c180",
     "grade": false,
     "grade_id": "cell-404e9c0d68a46c7c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-4-Task-2\n",
    "loss = None\n",
    "\n",
    "# Model Loss\n",
    "# Store the model's loss from trained above\n",
    "\n",
    "# Exercise 4 | Task 2\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "loss = losses[-1]\n",
    "# raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "AUJwO-z2LORt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe4b6e1a7da659d7d7bb61358f49fe84",
     "grade": false,
     "grade_id": "cell-cd972e8c828f74d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "7281c5d3-394a-4209-c611-22c318a54f4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037509294485466346"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rcMS1UgA0-G1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f502d775a57040c58d4ee2ec8f3023d",
     "grade": true,
     "grade_id": "cell-2c02ab4a9929d13a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "#INTENTIONALLY LEFT BLANK\n",
    "assert loss is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "h50t4Y7f0-G1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d560f9d70599bdd447567969c6bb2f08",
     "grade": false,
     "grade_id": "cell-8989e398a4400b6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, after we performed some preprocessing and model training steps, then we will start working on the model inferencing. We will see how well the model predicts the results. Also, we will discover what can be the possible solution to this problem.\n",
    "\n",
    "If we look at the model training results, we can see that the model is not performing really well. This may be because the LSTM network we are using is not able to learn the appropriate feature inputs. The no. of tokens is also pretty large which is giving the model a hard time to learn the input feature itself. So, the possible solution to these problems could be the `Attention Mechanisms`. We have not used attention mechanism, however if we use attention mechanism the result will surely turn out better.\n",
    "\n",
    "Moreover, we can validate the performance of the model by also inferencing on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vm-p0L85w6Mi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c8a39c7744b369949a86787e8834f7f",
     "grade": false,
     "grade_id": "cell-c942df3936e27c26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Decode Sample Sequences\n",
    "\n",
    "Following is the code to decode the input sequence to the machine translation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SEf9I1brw6Mi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0b45c69b73e5f81bf61c8626dadf94",
     "grade": false,
     "grade_id": "cell-5ed91b4ae4003424",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(Encoder(num_encoder_tokens, latent_dim, latent_dim), Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens))\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"lstm_seq2seq\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "def decode_sequence(sentence, max_length=50):\n",
    "    model.eval()\n",
    "    # lower, removing punctuations,\n",
    "    tokens =  (''.join(char for char in re.sub(\" +\", \" \", re.sub(\"'\", '', sentence).lower()) if char not in sets_of_punctuations)).split()\n",
    "\n",
    "    text_to_indices = [ input_token_index[token] for token in tokens]\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    outputs = [target_token_index[\"<START>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, ( hidden, cell ) = model.Decoder_LSTM(previous_word, (hidden, cell))\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if best_guess == \"<END>\":\n",
    "            break\n",
    "\n",
    "    translated_sentence = [reverse_target_char_index.get(idx, '<PAD>') for idx in outputs]\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nlUCxJsnw6Mj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "763c22c34ded6325c5ad21a2a9355592",
     "grade": false,
     "grade_id": "cell-c83a2b40557db068",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluation on Train Dataset\n",
    "\n",
    "Generating the sample to check some of the results predicted by the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "C_pmnLSGw6Mk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62ea65b73b7feb701332ebb26bccf2e2",
     "grade": false,
     "grade_id": "cell-5ecd5fc414a45548",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "327e2da8-1247-4ac9-e671-70d90a208e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: thats so perfect\n",
      "Actual Chinese Translation: <START> 那是完美的。 <END>\n",
      "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "t9-tBDjSw6Mk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cb0841aa20be247dc2cfa65c9ff8f81",
     "grade": false,
     "grade_id": "cell-ed8c1f20e44cf9ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "9b8d0184-59f8-4d08-cb46-570858e190cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: he worked very hard\n",
      "Actual Chinese Translation: <START> 他工作很努力。 <END>\n",
      "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "3TZxb_9Yw6Ml",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5fa51f0d95647f9eabb3536d3f3ffc8",
     "grade": false,
     "grade_id": "cell-415bd9a5589e425e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8659331a-cbf0-404d-b6b7-188053fb27da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: im not afraid of death\n",
      "Actual Chinese Translation: <START> 我不怕死。 <END>\n",
      "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "udM3JsI9w6Ml",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0a03d70e00916d5e4b79b1f091cb4e",
     "grade": false,
     "grade_id": "cell-7fcb2d3381bba963",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "04154953-2d2d-4c20-ec46-055651f1688d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: its really not important\n",
      "Actual Chinese Translation: <START> 真的不重要。 <END>\n",
      "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "dCL7Qdt5w6Mm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f36cbe941bac7f99dbc50e5e80d1c331",
     "grade": false,
     "grade_id": "cell-5e36305a19daeb11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "b2bf1b00-cd91-490d-9bf8-c6e60b74ea13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: whats not necessary\n",
      "Actual Chinese Translation: <START> 什麼是不必要的 <END>\n",
      "Predicted Chinese Translation: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
    "print('Predicted Chinese Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eGmUTVPS0-G3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4482e01ff125db80d9d6e06049834443",
     "grade": false,
     "grade_id": "cell-b60c247b0c3f991f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "CONGRATULATIONS!!! on completing the Assignment."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
