{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Title Generation of Nepali News articles using Seq2Seq with Attention Mechanism***\n"
      ],
      "metadata": {
        "id": "LkpYhlOp7nr1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S36HboFt7l07"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data from Drive\n",
        "\n",
        "I have a dataset containing News articles, their titles along with their published date & id. Currently, I am trying to predict title of news given its contents, the id and published date are of no use to us. We will drop those columns but first, let's import the data."
      ],
      "metadata": {
        "id": "Gy5bsJQN_FHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgpamsHY7nGX",
        "outputId": "79f32145-321a-4cee-9696-336f6420757e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/News Data/news_big.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAr38sZh7w4g",
        "outputId": "77465685-dd6d-4679-cca3-b4bd013c42b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0a6e96df579c>:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/drive/MyDrive/News Data/news_big.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "frfsdOpz8J5r",
        "outputId": "072151ee-0475-4210-fc86-1042cbe4f773"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                 date_published  \\\n",
              "0  208422p1   असार ३०, २०७९ बिहिबार ११:०:०   \n",
              "1  159079p1  असार ५, २०७७ शुक्रबार १२:४८:०   \n",
              "2  157801p1    जेठ २३, २०७७ शुक्रबार ७:०:०   \n",
              "3  157795p1   जेठ २३, २०७७ शुक्रबार ५:५९:०   \n",
              "4  157001p1    जेठ १४, २०७७ बुधबार १३:३२:०   \n",
              "\n",
              "                                      title  \\\n",
              "0            सरकारप्रतिको गिर्दो जनविश्वास।   \n",
              "1                    लद्दाखमा चीनको लक्ष्य।   \n",
              "2         आगामी दिनमा बसाल्नुपर्ने आनीबानी।   \n",
              "3               आधुनिक अन्धकार युगमा पिरती।   \n",
              "4  शक्तिशाली देशको कोरोनाविरुद्ध कमजोर कदम।   \n",
              "\n",
              "                                                news  \n",
              "0  जनताको विश्वास र बैधतामा शासन गर्ने सरकारहरू ज...  \n",
              "1  अहिले लद्दाख संकटलाई लिएर भारतमा भएको बहस एउटै...  \n",
              "2  पहिलाको जीवन सरल थियो। न मुखमा मास्क चाहिन्थ्य...  \n",
              "3    जन्मनेबित्तिकै मुहारमा जातीयताको चिह्न लगाइद...  \n",
              "4  अमेरिकाका डोनाल्ड ट्रम्प, रुसका भ्लादिमिर पुटि...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4038e9e7-acab-48b3-addd-2bb3d0876082\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date_published</th>\n",
              "      <th>title</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208422p1</td>\n",
              "      <td>असार ३०, २०७९ बिहिबार ११:०:०</td>\n",
              "      <td>सरकारप्रतिको गिर्दो जनविश्वास।</td>\n",
              "      <td>जनताको विश्वास र बैधतामा शासन गर्ने सरकारहरू ज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>159079p1</td>\n",
              "      <td>असार ५, २०७७ शुक्रबार १२:४८:०</td>\n",
              "      <td>लद्दाखमा चीनको लक्ष्य।</td>\n",
              "      <td>अहिले लद्दाख संकटलाई लिएर भारतमा भएको बहस एउटै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>157801p1</td>\n",
              "      <td>जेठ २३, २०७७ शुक्रबार ७:०:०</td>\n",
              "      <td>आगामी दिनमा बसाल्नुपर्ने आनीबानी।</td>\n",
              "      <td>पहिलाको जीवन सरल थियो। न मुखमा मास्क चाहिन्थ्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>157795p1</td>\n",
              "      <td>जेठ २३, २०७७ शुक्रबार ५:५९:०</td>\n",
              "      <td>आधुनिक अन्धकार युगमा पिरती।</td>\n",
              "      <td>जन्मनेबित्तिकै मुहारमा जातीयताको चिह्न लगाइद...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>157001p1</td>\n",
              "      <td>जेठ १४, २०७७ बुधबार १३:३२:०</td>\n",
              "      <td>शक्तिशाली देशको कोरोनाविरुद्ध कमजोर कदम।</td>\n",
              "      <td>अमेरिकाका डोनाल्ड ट्रम्प, रुसका भ्लादिमिर पुटि...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4038e9e7-acab-48b3-addd-2bb3d0876082')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4038e9e7-acab-48b3-addd-2bb3d0876082 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4038e9e7-acab-48b3-addd-2bb3d0876082');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7fbbab4-5a90-40fb-a960-27a45960e09a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7fbbab4-5a90-40fb-a960-27a45960e09a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7fbbab4-5a90-40fb-a960-27a45960e09a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop([\"id\", \"date_published\"], axis=1, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bhZpJ0P88LGE",
        "outputId": "356dfebc-a722-4866-f38e-3a920edc4d78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      title  \\\n",
              "0            सरकारप्रतिको गिर्दो जनविश्वास।   \n",
              "1                    लद्दाखमा चीनको लक्ष्य।   \n",
              "2         आगामी दिनमा बसाल्नुपर्ने आनीबानी।   \n",
              "3               आधुनिक अन्धकार युगमा पिरती।   \n",
              "4  शक्तिशाली देशको कोरोनाविरुद्ध कमजोर कदम।   \n",
              "\n",
              "                                                news  \n",
              "0  जनताको विश्वास र बैधतामा शासन गर्ने सरकारहरू ज...  \n",
              "1  अहिले लद्दाख संकटलाई लिएर भारतमा भएको बहस एउटै...  \n",
              "2  पहिलाको जीवन सरल थियो। न मुखमा मास्क चाहिन्थ्य...  \n",
              "3    जन्मनेबित्तिकै मुहारमा जातीयताको चिह्न लगाइद...  \n",
              "4  अमेरिकाका डोनाल्ड ट्रम्प, रुसका भ्लादिमिर पुटि...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-147570a2-042c-4967-af8d-5ae0bfb70a0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>सरकारप्रतिको गिर्दो जनविश्वास।</td>\n",
              "      <td>जनताको विश्वास र बैधतामा शासन गर्ने सरकारहरू ज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>लद्दाखमा चीनको लक्ष्य।</td>\n",
              "      <td>अहिले लद्दाख संकटलाई लिएर भारतमा भएको बहस एउटै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>आगामी दिनमा बसाल्नुपर्ने आनीबानी।</td>\n",
              "      <td>पहिलाको जीवन सरल थियो। न मुखमा मास्क चाहिन्थ्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>आधुनिक अन्धकार युगमा पिरती।</td>\n",
              "      <td>जन्मनेबित्तिकै मुहारमा जातीयताको चिह्न लगाइद...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>शक्तिशाली देशको कोरोनाविरुद्ध कमजोर कदम।</td>\n",
              "      <td>अमेरिकाका डोनाल्ड ट्रम्प, रुसका भ्लादिमिर पुटि...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-147570a2-042c-4967-af8d-5ae0bfb70a0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-147570a2-042c-4967-af8d-5ae0bfb70a0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-147570a2-042c-4967-af8d-5ae0bfb70a0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-adeac90b-6eff-4920-957c-a90f68d371b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-adeac90b-6eff-4920-957c-a90f68d371b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-adeac90b-6eff-4920-957c-a90f68d371b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQxQ9iui6-z",
        "outputId": "1d75a917-d882-46d2-ac2a-5f5f26fb96a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(226432, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(10000)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOc0INYM8eIL",
        "outputId": "df9f81a1-081e-4356-b90a-af92e54f0e0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[25].title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yhTbIqav8jTb",
        "outputId": "f842f943-b9f8-4061-8fff-5ed90c051b89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'श्रीमानको जो आदेश।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[25].news"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "buEcT_zf8m9I",
        "outputId": "15d7c015-2148-40df-c361-a7b5ca6c1011"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  केही दिनयता सर्वोच्च अदालत पत्रकारहरूप्रति अचम्मलाग्दो गरी असहिष्णु देखिँदै आएको छ । सर्वोच्चको यो असहिष्णुताको रहस्य बुझिनसक्नु छ ।   सधैँजसो अदालतको आदेश, फैसलाबारे बुझ्न जाने पत्रकार समूहलाई अस्ति मंगलबार अस्वभाविक रूपमा इजलास प्रवेश गर्नै दिइएन । खुला इजलास भनिने उक्त स्थानमा पुग्न सर्वोच्चले पत्रकारका लागि निकै कठीन बनाइदियो ।   इजलास प्रवेश त परको कुरा, सर्वोच्च अदालत परिसर छिर्नै पत्रकारका लागि मंगलबार निकै कडाइ थियो । मूलगेटमै सुरक्षाकर्मीले पत्रकारहरुको कडा खानतलासी लिए र क्यामेरा त्यहीं छाड्न लगाएर बल्ल भित्र छिराए ।   त्यसरी बल्लतल्ल छिरेका पत्रकारहरु सर्वोच्चको भुइँतलाबाट माथि उक्लन त पाउँदै पाएनन् । सर्वोच्च आफैँले पत्रकारहरुलाई एउटा पास दिएको थियो, मंगलबारदेखि त सर्वोच्चले त्यसलाई खोटो नै बनाइदियो । सर्वोच्चकै छाप र प्रवक्ताको हस्ताक्षर भएको त्यो पास अब सर्वोच्चकै सहप्रवक्ता हेमन्त रावलका शब्दमा ‘प्रवक्ताको कार्यकक्षसम्म पुग्नमात्र’ प्रयोग गर्न सकिन्छ ।   ‘यो पासले तपाईँहरू यहाँसम्म आउन सक्नुहुन्छ,’ रावलले आफ्नै कार्यकक्षमा भने, ‘सुरक्षाकर्मीहरुले सुरक्षाको समस्या देखाएपछि अब इजलास जान छुट्टै पास लिनुपर्छ ।’ रावलका भनाइमा प्रत्येक इजलास छिर्न बेग्लाबेग्लै पास लिनुपर्छ ।   कस्तो अव्यवहारिकता ?   सर्वोच्च अदालतमा अहिले दस न्यायाधीश कार्यरत छन् । प्रत्येक दिन १० वटै इजलासमा मुद्दाको सुनुवाइ हुन्छ । सर्वोच्चसम्म आइपुगेका सबै मुद्दा पत्रकारका लागि सूचनाका हिसाब र समाचारका विषयले उत्तिकै महत्व राख्छन् । प्रत्येक दिन ती दसै इजलास घुम्नुपर्छ, बहस सुन्नुपर्छ वा भइसकेका फैसलाबारे बुझ्न इजलासको पहुँचमा बस्नुपर्छ ।   तर, पत्रकारले अब सर्वोच्च अदालत परिसरमा खुम्चिनुपर्छ । प्रत्येक इजलास जान छुट्टाछुट्टै पास लिनुपर्छ, त्यो पनि सुरक्षाकर्मीबाटै । सुरक्षाकर्मीबाट दैनिक दसवटा पास जारी गराउनु व्यवहारिक होला ?  सूचनाको हक भन्ने पनि कुनै चिज अस्तित्वमा छ यो मुलुकमा ?   सर्वोच्चले यो बन्देज लगाउनुको पृष्ठभूमि पूर्वमुख्यसचिव लोकमान सिंह कार्कीको मुद्दाको सुनुवाइ हो । त्यो दिन सोमबार, कार्कीविरुद्धको अन्तरिम आदेश खारेज हुनुअघि इजलासमै बहस सुनिरहेका न्यायाधीश गिरीशचन्द्र लालले कान्तिपुर संवाददाता घनश्याम खड्कालाई भने, ‘तपाईं गन्जी लगाएर इजलासमा नबस्नुस् ।’ खड्का इजलास छाड्न बाध्य भए जबकी त्यही इजलासमा त्यस्तै टिसर्ट लगाएका अन्य पत्रकार लालकै सामुन्ने बसिरहेकै थिए ।   वकिलहरूले कार्कीको मुद्दामा ‘कान्तिपुर पत्रिकामा समाचार आएकै प्रमाण लिएर रिट पर्छ’ भनिरहेकै पृष्ठभूमिमा न्यायाधीशले त्यही पत्रिकाको पत्रकारलाई ठाडै ‘इजलासमा नबस्नुस्’ भन्दा खस्रै सुनियो । कतिपयले त यसलाई ‘ठाडो र लज्जास्पद’ नै भने ।   समूहमा बसेर बहस सुनिरहेको कुनै पनि व्यक्तिलाई ड्रेस कोड नतोकेको इजलासमा ठाडै नबस्न निर्देशन दिनुमा श्रीमान्को ‘सनकपन’ हो कि ?  सर्वोच्च अदालतले ड्रेस कोड नतोकेको सन्दर्भमा आएको श्रीमान्को यो वचनले त्यस दिन त एकजना पत्रकारमात्रै इजलास जान रोकिए, भोलिपल्टदेखि त त्यसको तारो अन्य पत्रकारहरुसम्मै आइपुग्यो । कोही पनि इजलास जानै पाएनन् । बुधबार त सार्वजनिक बिदा थियो, बिहीबार पनि कुनै पत्रकार इजलास छिर्न पाएनन् ।   विश्वव्यापी रूपमा खुला इजलासको अवधारणा आइरहेका बेला सूचनाका सम्वाहक पत्रकारलाई रोक लगाउनु भनेको शब्दमा स्वतन्त्र न्यायपालिकाको वकालत गर्ने अदालत आफैंले त्यसलाई व्यवहारमा लागू गर्न नसक्नु हो ।  अदालतको सुरक्षालाई ध्यानमा राखेर सुरक्षा व्यवस्था कडा गर्नु व्यवहारिक होला तर अदालतबाटै जारी भएको पासबाट समेत इजलास जान नदिनु भनेको नियोजित रुपमै पत्रकारलाई सूचनाबाट बन्देज लगाउन खोजेको हो । स्वतन्त्र न्यायपालिका र स्वतन्त्र प्रेसबीच रहँदै आएको सुमधुर र सहयोगी सम्बन्ध यो घटनाले भड्काएको छ । वैमनस्यता र असहयोगको भावना फैलाएको छ । सूचनाको हककै व्याख्या गर्ने सर्वोच्च आफैँले सूचनाबाट बन्देज लगाउने परिपाटी बनाउनु कत्तिको हितकर हो ?  अदालतले पत्रकारलाई लगाएको यो अंकुश किन पनि चित्तबुझ्दो छैन भने एक वर्षअघि सर्वोच्चका बहालवाला न्यायाधीश रणबहादुर बमलाई दिनदहाडै गोली हानी हत्या गरिँदासमेत पत्रकारलाई इजलास पहुँच सहज थियो । त्यत्तिबेला अदालत सुरक्षाका दृष्टिकोणले अत्यन्त संवेदनशील थियो ।  स्वतन्त्र न्यायपालिका र स्वतन्त्र प्रेसबाट मात्रै लोकतन्त्र बलियो हुन्छ भन्ने राय सर्वोच्च अदालतबाट प्रेषित विज्ञप्तिमा सधैँ लेखिएको हुन्छ । न्यायमूर्तिहरु अदालतको औपचारिक कार्यक्रमहरुमा आफ्ना मन्तव्य दिँदा स्वतन्त्र प्रेस र स्वतन्त्र न्यायपालिका एकअर्काका परिपुरक भएको टिप्पणी गर्छन् । स्वतन्त्र प्रेसको वकालत गर्नेहरुले अस्वभाविक रुपमा इजलास जानै पो असहज बनाइदिए ।  हेटौँडा महाधिवेशनमा उठेको माओवादी अध्यक्ष पुष्पकमल दाहालको अनुमानबाहिरको प्रस्ताव र त्यसपछि विकसित घटनाक्रमबाट चर्को विवादबीच प्रधानन्यायाधीश खिलराज रेग्मी चुनावी प्रयोजनका लागि मन्त्रिपरिषद् अध्यक्ष भए ।  प्रधानन्यायाधीश रेग्मीको व्यक्तिगत प्रधानमन्त्री हुन चाहेको वक्तब्य सर्वोच्चका सहप्रवक्तामार्फत् आयो । व्यक्तिगत स्वार्थको प्रधानमन्त्री मोहलाई प्रधानन्यायाधीशले सर्वोच्चको विज्ञप्तिमार्फत् संस्थागत बनाए । चर्को आलोचना भयो । अदृश्य रुपमा न्यायपालिकामा पत्रकारलाई अवरोध र असहयोग त्यही बेलादेखि हुँदै आएको थियो ।  प्रधानन्यायाधधीश सर्वोच्चको वल्लो घरबाट प्रधानमन्त्री कार्यालयको पल्लो घर सर्दा स्वतन्त्र न्यायपालिकाले पाइला डगमगाएको आभास भएको थियो । यसले शक्तिपृथकीकरणको सिद्धान्तलाई माथ मात्रै खुवाएन, बिस्तारै न्यायमूर्तिहरुले आचारसंहिताबाट माथि उठेर भविष्यको स्वार्थ हेर्ने अभ्यास सुरु गरे । त्यही अभ्यासको अर्को रुप प्रेसलाई रोक्न खोज्नु भएको छ ।  कुनै असायमिक वा सर्वोच्चको सुरक्षामा खलबल आउने घटनापछि पत्रकारलाई इजलासमा बन्देज लगाएको भए त्यसलाई जायज मान्न सकिन्थ्यो ।  शाही आयोग खारेज, संविधानसभाको म्यादसम्बन्धी सर्वोच्चका फैसलाहरु र सरकारका गैरकानुनी निर्णयमा न्यायपालिकाले लगाउने गरेको अकुंशले सधैँ स्वतन्त्र न्यायपालिकाको अस्मितालाई जोगाउँदै आएको छ । विश्वव्यापी रुपमा स्वतन्त्र न्यायपालिका र त्यसमा पनि खुला इजलासको अवधारणा विकसित भइरहेको बेला एउटा सूचनाकर्मीलाई सर्वोच्चबाटै जारी भएको पासले इजलासमा बहस सुन्ने अधिकार दिँदैन भने त्यसले स्वतन्त्र न्यायपालिकाको वकालत कसरी गर्ला ?  विभिन्न मुलुकका अदालत भ्रमणबाट फर्किएपछि ‘त्यहाँका इजलासमा पत्रकारका लागि यस्तो व्यवस्था रहेछ’ भनेर श्रीमान्हरु नै सुनाउँछन् । तर, अदालतमा यसरी पत्रकारलाई बन्देज लगाउन खोज्नुले श्रीमान्हरुको पुरातनपन्थी सोच जति नै विदेश घुमे पनि बदलिएको रहेनछ भन्ने स्पष्ट हुन्छ ।  सूचना प्रविधि अनियन्त्रित रुपमा विकसित भइरहेको बेला सूचनामा अंकुश लगाउन सकिन्छ भन्ने सोच्नु सर्वोच्चको गलत बुझाइ हो । हाम्रो अनुभवमा न्यायाधीशहरु आफूले गरेको फैसला इमेल गर्छन् । पत्रकारको जातै सूचना जसरी भए पनि बाहिर ल्याउन खोज्ने हुन्छ । जति बन्देज लगाइन्छ, सूचना त्यति महत्वपूर्ण लाग्छ । सर्वोच्चको यस्तो बन्देजले भोलि न्यायपालिकाको अति गोप्य सूचना अपरिपक्व अवस्थामै गलत बाटोबाट बाहिर आउँछन् । त्यसले न्यायपालिका र मिडियाबीचको सम्बन्ध चिसो पार्छ ।  सर्वोच्च अदालत प्रशासनले तातो रिस गरेर अव्यवहारिक रुपमा पत्रकारलाई इजलास जान बन्देज लगाउनुभन्दा अलि ठन्डा दिमागले सोचे पत्रकार प्रवेशलाई नियमन गर्नु व्यवहारिक होला कि !,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "jZ-QDFpm_BDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  #remove punctuations\n",
        "  sentences = text.replace(\"\\n\", \" \").split(u\"।\")\n",
        "  f = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in sentences]\n",
        "  f = [x.strip() for x in f if len(x)>0]\n",
        "  return \" \".join(f)"
      ],
      "metadata": {
        "id": "fnLEclaR8qzO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also there are unicode like \\u200d and \\xa0, let's clean them. We will also remove emojis in this function\n",
        "def clean_text_unicode(text):\n",
        "    # Replace \\xa0 and \\u200d with a blank space\n",
        "    text = text.replace('\\xa0', ' ').replace('\\u200d', ' ').replace(\"’\",' ').replace(\"‘\",' ')\n",
        "\n",
        "\n",
        "    emojis = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    text = re.sub(emojis, '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "wfEOM9kP_vTS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = lambda x: clean_text_unicode(clean_text(x))"
      ],
      "metadata": {
        "id": "ujxnJ-9GBkjI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.news = data.news.apply(cleaner)\n",
        "data.title = data.title.apply(cleaner)"
      ],
      "metadata": {
        "id": "5fYDV_0mB92I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[25].news"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Lg5vHo8mCJl5",
        "outputId": "ce37838a-f3ec-4b09-a249-154b8490f8d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'केही दिनयता सर्वोच्च अदालत पत्रकारहरूप्रति अचम्मलाग्दो गरी असहिष्णु देखिँदै आएको छ सर्वोच्चको यो असहिष्णुताको रहस्य बुझिनसक्नु छ सधैँजसो अदालतको आदेश फैसलाबारे बुझ्न जाने पत्रकार समूहलाई अस्ति मंगलबार अस्वभाविक रूपमा इजलास प्रवेश गर्नै दिइएन खुला इजलास भनिने उक्त स्थानमा पुग्न सर्वोच्चले पत्रकारका लागि निकै कठीन बनाइदियो इजलास प्रवेश त परको कुरा सर्वोच्च अदालत परिसर छिर्नै पत्रकारका लागि मंगलबार निकै कडाइ थियो मूलगेटमै सुरक्षाकर्मीले पत्रकारहरुको कडा खानतलासी लिए र क्यामेरा त्यहीं छाड्न लगाएर बल्ल भित्र छिराए त्यसरी बल्लतल्ल छिरेका पत्रकारहरु सर्वोच्चको भुइँतलाबाट माथि उक्लन त पाउँदै पाएनन् सर्वोच्च आफैँले पत्रकारहरुलाई एउटा पास दिएको थियो मंगलबारदेखि त सर्वोच्चले त्यसलाई खोटो नै बनाइदियो सर्वोच्चकै छाप र प्रवक्ताको हस्ताक्षर भएको त्यो पास अब सर्वोच्चकै सहप्रवक्ता हेमन्त रावलका शब्दमा  प्रवक्ताको कार्यकक्षसम्म पुग्नमात्र  प्रयोग गर्न सकिन्छ  यो पासले तपाईँहरू यहाँसम्म आउन सक्नुहुन्छ  रावलले आफ्नै कार्यकक्षमा भने  सुरक्षाकर्मीहरुले सुरक्षाको समस्या देखाएपछि अब इजलास जान छुट्टै पास लिनुपर्छ   रावलका भनाइमा प्रत्येक इजलास छिर्न बेग्लाबेग्लै पास लिनुपर्छ कस्तो अव्यवहारिकता    सर्वोच्च अदालतमा अहिले दस न्यायाधीश कार्यरत छन् प्रत्येक दिन १० वटै इजलासमा मुद्दाको सुनुवाइ हुन्छ सर्वोच्चसम्म आइपुगेका सबै मुद्दा पत्रकारका लागि सूचनाका हिसाब र समाचारका विषयले उत्तिकै महत्व राख्छन् प्रत्येक दिन ती दसै इजलास घुम्नुपर्छ बहस सुन्नुपर्छ वा भइसकेका फैसलाबारे बुझ्न इजलासको पहुँचमा बस्नुपर्छ तर पत्रकारले अब सर्वोच्च अदालत परिसरमा खुम्चिनुपर्छ प्रत्येक इजलास जान छुट्टाछुट्टै पास लिनुपर्छ त्यो पनि सुरक्षाकर्मीबाटै सुरक्षाकर्मीबाट दैनिक दसवटा पास जारी गराउनु व्यवहारिक होला   सूचनाको हक भन्ने पनि कुनै चिज अस्तित्वमा छ यो मुलुकमा    सर्वोच्चले यो बन्देज लगाउनुको पृष्ठभूमि पूर्वमुख्यसचिव लोकमान सिंह कार्कीको मुद्दाको सुनुवाइ हो त्यो दिन सोमबार कार्कीविरुद्धको अन्तरिम आदेश खारेज हुनुअघि इजलासमै बहस सुनिरहेका न्यायाधीश गिरीशचन्द्र लालले कान्तिपुर संवाददाता घनश्याम खड्कालाई भने  तपाईं गन्जी लगाएर इजलासमा नबस्नुस्   खड्का इजलास छाड्न बाध्य भए जबकी त्यही इजलासमा त्यस्तै टिसर्ट लगाएका अन्य पत्रकार लालकै सामुन्ने बसिरहेकै थिए वकिलहरूले कार्कीको मुद्दामा  कान्तिपुर पत्रिकामा समाचार आएकै प्रमाण लिएर रिट पर्छ  भनिरहेकै पृष्ठभूमिमा न्यायाधीशले त्यही पत्रिकाको पत्रकारलाई ठाडै  इजलासमा नबस्नुस्  भन्दा खस्रै सुनियो कतिपयले त यसलाई  ठाडो र लज्जास्पद  नै भने समूहमा बसेर बहस सुनिरहेको कुनै पनि व्यक्तिलाई ड्रेस कोड नतोकेको इजलासमा ठाडै नबस्न निर्देशन दिनुमा श्रीमान्को  सनकपन  हो कि   सर्वोच्च अदालतले ड्रेस कोड नतोकेको सन्दर्भमा आएको श्रीमान्को यो वचनले त्यस दिन त एकजना पत्रकारमात्रै इजलास जान रोकिए भोलिपल्टदेखि त त्यसको तारो अन्य पत्रकारहरुसम्मै आइपुग्यो कोही पनि इजलास जानै पाएनन् बुधबार त सार्वजनिक बिदा थियो बिहीबार पनि कुनै पत्रकार इजलास छिर्न पाएनन् विश्वव्यापी रूपमा खुला इजलासको अवधारणा आइरहेका बेला सूचनाका सम्वाहक पत्रकारलाई रोक लगाउनु भनेको शब्दमा स्वतन्त्र न्यायपालिकाको वकालत गर्ने अदालत आफैंले त्यसलाई व्यवहारमा लागू गर्न नसक्नु हो अदालतको सुरक्षालाई ध्यानमा राखेर सुरक्षा व्यवस्था कडा गर्नु व्यवहारिक होला तर अदालतबाटै जारी भएको पासबाट समेत इजलास जान नदिनु भनेको नियोजित रुपमै पत्रकारलाई सूचनाबाट बन्देज लगाउन खोजेको हो स्वतन्त्र न्यायपालिका र स्वतन्त्र प्रेसबीच रहँदै आएको सुमधुर र सहयोगी सम्बन्ध यो घटनाले भड्काएको छ वैमनस्यता र असहयोगको भावना फैलाएको छ सूचनाको हककै व्याख्या गर्ने सर्वोच्च आफैँले सूचनाबाट बन्देज लगाउने परिपाटी बनाउनु कत्तिको हितकर हो   अदालतले पत्रकारलाई लगाएको यो अंकुश किन पनि चित्तबुझ्दो छैन भने एक वर्षअघि सर्वोच्चका बहालवाला न्यायाधीश रणबहादुर बमलाई दिनदहाडै गोली हानी हत्या गरिँदासमेत पत्रकारलाई इजलास पहुँच सहज थियो त्यत्तिबेला अदालत सुरक्षाका दृष्टिकोणले अत्यन्त संवेदनशील थियो स्वतन्त्र न्यायपालिका र स्वतन्त्र प्रेसबाट मात्रै लोकतन्त्र बलियो हुन्छ भन्ने राय सर्वोच्च अदालतबाट प्रेषित विज्ञप्तिमा सधैँ लेखिएको हुन्छ न्यायमूर्तिहरु अदालतको औपचारिक कार्यक्रमहरुमा आफ्ना मन्तव्य दिँदा स्वतन्त्र प्रेस र स्वतन्त्र न्यायपालिका एकअर्काका परिपुरक भएको टिप्पणी गर्छन् स्वतन्त्र प्रेसको वकालत गर्नेहरुले अस्वभाविक रुपमा इजलास जानै पो असहज बनाइदिए हेटौँडा महाधिवेशनमा उठेको माओवादी अध्यक्ष पुष्पकमल दाहालको अनुमानबाहिरको प्रस्ताव र त्यसपछि विकसित घटनाक्रमबाट चर्को विवादबीच प्रधानन्यायाधीश खिलराज रेग्मी चुनावी प्रयोजनका लागि मन्त्रिपरिषद् अध्यक्ष भए प्रधानन्यायाधीश रेग्मीको व्यक्तिगत प्रधानमन्त्री हुन चाहेको वक्तब्य सर्वोच्चका सहप्रवक्तामार्फत् आयो व्यक्तिगत स्वार्थको प्रधानमन्त्री मोहलाई प्रधानन्यायाधीशले सर्वोच्चको विज्ञप्तिमार्फत् संस्थागत बनाए चर्को आलोचना भयो अदृश्य रुपमा न्यायपालिकामा पत्रकारलाई अवरोध र असहयोग त्यही बेलादेखि हुँदै आएको थियो प्रधानन्यायाधधीश सर्वोच्चको वल्लो घरबाट प्रधानमन्त्री कार्यालयको पल्लो घर सर्दा स्वतन्त्र न्यायपालिकाले पाइला डगमगाएको आभास भएको थियो यसले शक्तिपृथकीकरणको सिद्धान्तलाई माथ मात्रै खुवाएन बिस्तारै न्यायमूर्तिहरुले आचारसंहिताबाट माथि उठेर भविष्यको स्वार्थ हेर्ने अभ्यास सुरु गरे त्यही अभ्यासको अर्को रुप प्रेसलाई रोक्न खोज्नु भएको छ कुनै असायमिक वा सर्वोच्चको सुरक्षामा खलबल आउने घटनापछि पत्रकारलाई इजलासमा बन्देज लगाएको भए त्यसलाई जायज मान्न सकिन्थ्यो शाही आयोग खारेज संविधानसभाको म्यादसम्बन्धी सर्वोच्चका फैसलाहरु र सरकारका गैरकानुनी निर्णयमा न्यायपालिकाले लगाउने गरेको अकुंशले सधैँ स्वतन्त्र न्यायपालिकाको अस्मितालाई जोगाउँदै आएको छ विश्वव्यापी रुपमा स्वतन्त्र न्यायपालिका र त्यसमा पनि खुला इजलासको अवधारणा विकसित भइरहेको बेला एउटा सूचनाकर्मीलाई सर्वोच्चबाटै जारी भएको पासले इजलासमा बहस सुन्ने अधिकार दिँदैन भने त्यसले स्वतन्त्र न्यायपालिकाको वकालत कसरी गर्ला   विभिन्न मुलुकका अदालत भ्रमणबाट फर्किएपछि  त्यहाँका इजलासमा पत्रकारका लागि यस्तो व्यवस्था रहेछ  भनेर श्रीमान्हरु नै सुनाउँछन् तर अदालतमा यसरी पत्रकारलाई बन्देज लगाउन खोज्नुले श्रीमान्हरुको पुरातनपन्थी सोच जति नै विदेश घुमे पनि बदलिएको रहेनछ भन्ने स्पष्ट हुन्छ सूचना प्रविधि अनियन्त्रित रुपमा विकसित भइरहेको बेला सूचनामा अंकुश लगाउन सकिन्छ भन्ने सोच्नु सर्वोच्चको गलत बुझाइ हो हाम्रो अनुभवमा न्यायाधीशहरु आफूले गरेको फैसला इमेल गर्छन् पत्रकारको जातै सूचना जसरी भए पनि बाहिर ल्याउन खोज्ने हुन्छ जति बन्देज लगाइन्छ सूचना त्यति महत्वपूर्ण लाग्छ सर्वोच्चको यस्तो बन्देजले भोलि न्यायपालिकाको अति गोप्य सूचना अपरिपक्व अवस्थामै गलत बाटोबाट बाहिर आउँछन् त्यसले न्यायपालिका र मिडियाबीचको सम्बन्ध चिसो पार्छ सर्वोच्च अदालत प्रशासनले तातो रिस गरेर अव्यवहारिक रुपमा पत्रकारलाई इजलास जान बन्देज लगाउनुभन्दा अलि ठन्डा दिमागले सोचे पत्रकार प्रवेशलाई नियमन गर्नु व्यवहारिक होला कि'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like the text is almost clean. We will be ignoring other data impurities and will continue with other tasks.**"
      ],
      "metadata": {
        "id": "epR-_8CiFGB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Split, Tokenization and Vocabulary Creation"
      ],
      "metadata": {
        "id": "_ZOd2nqqFcAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"news\"], data[\"title\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5_A4QATLFx8_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_news = X_train.apply(lambda x:x.split()).apply(len).max()\n",
        "max_words_news"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgwLV-uBF7My",
        "outputId": "fc9a0d42-0a9d-4b77-9ab8-0d6739c6763d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5151"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words_title = y_train.apply(lambda x:x.split()).apply(len).max()\n",
        "max_words_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcTiCzuxF_4Y",
        "outputId": "cbfd47d1-f388-4680-930b-de48fc032d9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter()\n",
        "for X in X_train:\n",
        "  counter.update(X.split())\n",
        "for y in y_train:\n",
        "  counter.update(y.split())"
      ],
      "metadata": {
        "id": "e_4SKLygGEOG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))"
      ],
      "metadata": {
        "id": "KfVa_sSbGJUf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs.set_default_index(vocabs['<unk>'])"
      ],
      "metadata": {
        "id": "N9agdXraGvo-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs[\"जनताको\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFbt5rliGyam",
        "outputId": "34472c53-ee81-4265-ff0a-91d44cf0aa58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1539"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X,y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        news = self.X.iloc[idx]\n",
        "        title = self.y.iloc[idx]\n",
        "\n",
        "        news_indices = [vocabs[word] for word in news.split()]\n",
        "        title_indices = [vocabs[word] for word in title.split()]\n",
        "\n",
        "        if len(news_indices)<max_words_news:\n",
        "            news_indices = news_indices + [1]*(max_words_news - len(news_indices))\n",
        "\n",
        "        if len(title_indices)<max_words_title:\n",
        "            title_indices = title_indices + [1]*(max_words_title - len(title_indices))\n",
        "        return torch.tensor(news_indices), torch.tensor(title_indices)"
      ],
      "metadata": {
        "id": "AeZ71-zXG06X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(X_train,y_train)\n",
        "test_dataset = MyDataset(X_test,y_test)"
      ],
      "metadata": {
        "id": "xeO4zhEKG5R6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "bWesKpq1gOX1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[25][0], test_dataset[25][1]  # news and title in 25th index of train dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsn1-VFxOG7C",
        "outputId": "8c6c6511-2850-4d68-8845-a03dda791b44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([586,   0,   0,  ...,   1,   1,   1]),\n",
              " tensor([    0, 16480,     9,     0,    22,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2WEihjqOKA8",
        "outputId": "734b65c1-5fa7-40c6-e638-58cee6739fa5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 586, 2044, 1752,  ...,    1,    1,    1]),\n",
              " tensor([2047, 2048, 7328, 1466, 2056, 2057, 2058,  128,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch dataset object use index to return item, so need to reset non-continuoues index of divided dataset\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ab8pjABSOlKE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Building Model***"
      ],
      "metadata": {
        "id": "6uh0bx4jQxxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Encoder***"
      ],
      "metadata": {
        "id": "ssayga02Q2GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout): # input_dim = source vocab size\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "    self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
        "\n",
        "    self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim) # enc_hid_dim *2 because of bidirectional\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, src):\n",
        "\n",
        "    # src = [seq_len, batch_size]\n",
        "    embeddings = self.dropout(self.embedding(src)) # -> [seq_len, batch_size, emb_dim]\n",
        "\n",
        "    outputs, hidden = self.rnn(embeddings)\n",
        "\n",
        "    #outputs = [src len, batch size, hid dim * num directions]\n",
        "    #hidden = [n layers * num directions, batch size, hid dim]\n",
        "    #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "    #outputs are always from the last layer\n",
        "\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "    #outputs = [src len, batch size, enc hid dim * 2]\n",
        "    #hidden = [batch size, dec hid dim]\n",
        "\n",
        "    return outputs, hidden"
      ],
      "metadata": {
        "id": "C7rOSXQqQryU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Attention***"
      ],
      "metadata": {
        "id": "v0KPqtLPVET4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
        "\n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        #attention= [batch size, src len]\n",
        "\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "cz_FjwgQVBzl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Decoder***"
      ],
      "metadata": {
        "id": "_2mVX3zUlObM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        #input = [1, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "\n",
        "        #a = [batch size, src len]\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        #a = [batch size, 1, src len]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        print(\"embedded size:\", embedded.size())\n",
        "        print(\"weighted size:\", weighted.size())\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "\n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "\n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "\n",
        "        #prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction, hidden.squeeze(0)"
      ],
      "metadata": {
        "id": "xFAAUEjyfhuc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Seq2Seq with Attention***"
      ],
      "metadata": {
        "id": "cDWh-hEYlSDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "fYz3m1wofluc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "0vGLk-3UfoSz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Model Hyperparameters*"
      ],
      "metadata": {
        "id": "I_oQGq421ftF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocabs)\n",
        "OUTPUT_DIM = len(vocabs)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "metadata": {
        "id": "hNNYWEOvfrh9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7mXUugAftaI",
        "outputId": "9e487a01-9ae0-4422-e772-17ad4768209a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(19832, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(19832, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=19832, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HSNoTC8fvq4",
        "outputId": "3274c2af-e783-4d89-9488-d339cb034754"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 52,146,040 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "0jAJ6-bZfyqq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = 1)"
      ],
      "metadata": {
        "id": "o2iqO42Zf2HY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function\n",
        "\n"
      ],
      "metadata": {
        "id": "LywEOWP215y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch[0].to(device)\n",
        "        trg = batch[1].to(device)\n",
        "        # print(\"DEVICE\",src.get_device(),trg.get_device())\n",
        "\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "J598ES0kf4jp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Function"
      ],
      "metadata": {
        "id": "R64EZmDR1_OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch[0].to(device)\n",
        "            trg = batch[1].to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "1oZNn4Z1f6hN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "QK88Noy3f9w5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "NxpIeE4DgAL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ak33GEpFgGld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}